{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e127a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a54040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi in c:\\anaconda3\\lib\\site-packages (2024.8.30)\n",
      "Requirement already satisfied: optuna in c:\\anaconda3\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\anaconda3\\lib\\site-packages (from optuna) (1.13.2)\n",
      "Requirement already satisfied: colorlog in c:\\anaconda3\\lib\\site-packages (from optuna) (6.8.2)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from optuna) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda3\\lib\\site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\anaconda3\\lib\\site-packages (from optuna) (1.4.39)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda3\\lib\\site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in c:\\anaconda3\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: Mako in c:\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade certifi\n",
    "\n",
    "!pip install --trusted-host files.pythonhosted.org optuna\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae5c024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'fraudTest.csv',\n",
       " 'fraudTrain.csv',\n",
       " 'Fraudulent transactions-Bkp02Sept2024.ipynb',\n",
       " 'Fraudulent transactions.ipynb',\n",
       " 'fraud_detection_nn.pth',\n",
       " 'fraud_detection_nn_es.pth',\n",
       " 'LIME_implementation',\n",
       " 'LIME_implementation.zip',\n",
       " 'proj2',\n",
       " 'train_df.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e8ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"fraudTrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77cf984f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>...</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>...</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296670</th>\n",
       "      <td>1296670</td>\n",
       "      <td>2020-06-21 12:12:08</td>\n",
       "      <td>30263540414123</td>\n",
       "      <td>fraud_Reichel Inc</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>15.56</td>\n",
       "      <td>Erik</td>\n",
       "      <td>Patterson</td>\n",
       "      <td>M</td>\n",
       "      <td>162 Jessica Row Apt. 072</td>\n",
       "      <td>...</td>\n",
       "      <td>37.7175</td>\n",
       "      <td>-112.4777</td>\n",
       "      <td>258</td>\n",
       "      <td>Geoscientist</td>\n",
       "      <td>1961-11-24</td>\n",
       "      <td>440b587732da4dc1a6395aba5fb41669</td>\n",
       "      <td>1371816728</td>\n",
       "      <td>36.841266</td>\n",
       "      <td>-111.690765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296671</th>\n",
       "      <td>1296671</td>\n",
       "      <td>2020-06-21 12:12:19</td>\n",
       "      <td>6011149206456997</td>\n",
       "      <td>fraud_Abernathy and Sons</td>\n",
       "      <td>food_dining</td>\n",
       "      <td>51.70</td>\n",
       "      <td>Jeffrey</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>8617 Holmes Terrace Suite 651</td>\n",
       "      <td>...</td>\n",
       "      <td>39.2667</td>\n",
       "      <td>-77.5101</td>\n",
       "      <td>100</td>\n",
       "      <td>Production assistant, television</td>\n",
       "      <td>1979-12-11</td>\n",
       "      <td>278000d2e0d2277d1de2f890067dcc0a</td>\n",
       "      <td>1371816739</td>\n",
       "      <td>38.906881</td>\n",
       "      <td>-78.246528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296672</th>\n",
       "      <td>1296672</td>\n",
       "      <td>2020-06-21 12:12:32</td>\n",
       "      <td>3514865930894695</td>\n",
       "      <td>fraud_Stiedemann Ltd</td>\n",
       "      <td>food_dining</td>\n",
       "      <td>105.93</td>\n",
       "      <td>Christopher</td>\n",
       "      <td>Castaneda</td>\n",
       "      <td>M</td>\n",
       "      <td>1632 Cohen Drive Suite 639</td>\n",
       "      <td>...</td>\n",
       "      <td>32.9396</td>\n",
       "      <td>-105.8189</td>\n",
       "      <td>899</td>\n",
       "      <td>Naval architect</td>\n",
       "      <td>1967-08-30</td>\n",
       "      <td>483f52fe67fabef353d552c1e662974c</td>\n",
       "      <td>1371816752</td>\n",
       "      <td>33.619513</td>\n",
       "      <td>-105.130529</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296673</th>\n",
       "      <td>1296673</td>\n",
       "      <td>2020-06-21 12:13:36</td>\n",
       "      <td>2720012583106919</td>\n",
       "      <td>fraud_Reinger, Weissnat and Strosin</td>\n",
       "      <td>food_dining</td>\n",
       "      <td>74.90</td>\n",
       "      <td>Joseph</td>\n",
       "      <td>Murray</td>\n",
       "      <td>M</td>\n",
       "      <td>42933 Ryan Underpass</td>\n",
       "      <td>...</td>\n",
       "      <td>43.3526</td>\n",
       "      <td>-102.5411</td>\n",
       "      <td>1126</td>\n",
       "      <td>Volunteer coordinator</td>\n",
       "      <td>1980-08-18</td>\n",
       "      <td>d667cdcbadaaed3da3f4020e83591c83</td>\n",
       "      <td>1371816816</td>\n",
       "      <td>42.788940</td>\n",
       "      <td>-103.241160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296674</th>\n",
       "      <td>1296674</td>\n",
       "      <td>2020-06-21 12:13:37</td>\n",
       "      <td>4292902571056973207</td>\n",
       "      <td>fraud_Langosh, Wintheiser and Hyatt</td>\n",
       "      <td>food_dining</td>\n",
       "      <td>4.30</td>\n",
       "      <td>Jeffrey</td>\n",
       "      <td>Smith</td>\n",
       "      <td>M</td>\n",
       "      <td>135 Joseph Mountains</td>\n",
       "      <td>...</td>\n",
       "      <td>45.8433</td>\n",
       "      <td>-113.8748</td>\n",
       "      <td>218</td>\n",
       "      <td>Therapist, horticultural</td>\n",
       "      <td>1995-08-16</td>\n",
       "      <td>8f7c8e4ab7f25875d753b422917c98c9</td>\n",
       "      <td>1371816817</td>\n",
       "      <td>46.565983</td>\n",
       "      <td>-114.186110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1296675 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0 trans_date_trans_time               cc_num  \\\n",
       "0                 0   2019-01-01 00:00:18     2703186189652095   \n",
       "1                 1   2019-01-01 00:00:44         630423337322   \n",
       "2                 2   2019-01-01 00:00:51       38859492057661   \n",
       "3                 3   2019-01-01 00:01:16     3534093764340240   \n",
       "4                 4   2019-01-01 00:03:06      375534208663984   \n",
       "...             ...                   ...                  ...   \n",
       "1296670     1296670   2020-06-21 12:12:08       30263540414123   \n",
       "1296671     1296671   2020-06-21 12:12:19     6011149206456997   \n",
       "1296672     1296672   2020-06-21 12:12:32     3514865930894695   \n",
       "1296673     1296673   2020-06-21 12:13:36     2720012583106919   \n",
       "1296674     1296674   2020-06-21 12:13:37  4292902571056973207   \n",
       "\n",
       "                                    merchant       category     amt  \\\n",
       "0                 fraud_Rippin, Kub and Mann       misc_net    4.97   \n",
       "1            fraud_Heller, Gutmann and Zieme    grocery_pos  107.23   \n",
       "2                       fraud_Lind-Buckridge  entertainment  220.11   \n",
       "3         fraud_Kutch, Hermiston and Farrell  gas_transport   45.00   \n",
       "4                        fraud_Keeling-Crist       misc_pos   41.96   \n",
       "...                                      ...            ...     ...   \n",
       "1296670                    fraud_Reichel Inc  entertainment   15.56   \n",
       "1296671             fraud_Abernathy and Sons    food_dining   51.70   \n",
       "1296672                 fraud_Stiedemann Ltd    food_dining  105.93   \n",
       "1296673  fraud_Reinger, Weissnat and Strosin    food_dining   74.90   \n",
       "1296674  fraud_Langosh, Wintheiser and Hyatt    food_dining    4.30   \n",
       "\n",
       "               first       last gender                         street  ...  \\\n",
       "0           Jennifer      Banks      F                 561 Perry Cove  ...   \n",
       "1          Stephanie       Gill      F   43039 Riley Greens Suite 393  ...   \n",
       "2             Edward    Sanchez      M       594 White Dale Suite 530  ...   \n",
       "3             Jeremy      White      M    9443 Cynthia Court Apt. 038  ...   \n",
       "4              Tyler     Garcia      M               408 Bradley Rest  ...   \n",
       "...              ...        ...    ...                            ...  ...   \n",
       "1296670         Erik  Patterson      M       162 Jessica Row Apt. 072  ...   \n",
       "1296671      Jeffrey      White      M  8617 Holmes Terrace Suite 651  ...   \n",
       "1296672  Christopher  Castaneda      M     1632 Cohen Drive Suite 639  ...   \n",
       "1296673       Joseph     Murray      M           42933 Ryan Underpass  ...   \n",
       "1296674      Jeffrey      Smith      M           135 Joseph Mountains  ...   \n",
       "\n",
       "             lat      long  city_pop                                job  \\\n",
       "0        36.0788  -81.1781      3495          Psychologist, counselling   \n",
       "1        48.8878 -118.2105       149  Special educational needs teacher   \n",
       "2        42.1808 -112.2620      4154        Nature conservation officer   \n",
       "3        46.2306 -112.1138      1939                    Patent attorney   \n",
       "4        38.4207  -79.4629        99     Dance movement psychotherapist   \n",
       "...          ...       ...       ...                                ...   \n",
       "1296670  37.7175 -112.4777       258                       Geoscientist   \n",
       "1296671  39.2667  -77.5101       100   Production assistant, television   \n",
       "1296672  32.9396 -105.8189       899                    Naval architect   \n",
       "1296673  43.3526 -102.5411      1126              Volunteer coordinator   \n",
       "1296674  45.8433 -113.8748       218           Therapist, horticultural   \n",
       "\n",
       "                dob                         trans_num   unix_time  merch_lat  \\\n",
       "0        1988-03-09  0b242abb623afc578575680df30655b9  1325376018  36.011293   \n",
       "1        1978-06-21  1f76529f8574734946361c461b024d99  1325376044  49.159047   \n",
       "2        1962-01-19  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704   \n",
       "3        1967-01-12  6b849c168bdad6f867558c3793159a81  1325376076  47.034331   \n",
       "4        1986-03-28  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999   \n",
       "...             ...                               ...         ...        ...   \n",
       "1296670  1961-11-24  440b587732da4dc1a6395aba5fb41669  1371816728  36.841266   \n",
       "1296671  1979-12-11  278000d2e0d2277d1de2f890067dcc0a  1371816739  38.906881   \n",
       "1296672  1967-08-30  483f52fe67fabef353d552c1e662974c  1371816752  33.619513   \n",
       "1296673  1980-08-18  d667cdcbadaaed3da3f4020e83591c83  1371816816  42.788940   \n",
       "1296674  1995-08-16  8f7c8e4ab7f25875d753b422917c98c9  1371816817  46.565983   \n",
       "\n",
       "         merch_long  is_fraud  \n",
       "0        -82.048315         0  \n",
       "1       -118.186462         0  \n",
       "2       -112.154481         0  \n",
       "3       -112.561071         0  \n",
       "4        -78.632459         0  \n",
       "...             ...       ...  \n",
       "1296670 -111.690765         0  \n",
       "1296671  -78.246528         0  \n",
       "1296672 -105.130529         0  \n",
       "1296673 -103.241160         0  \n",
       "1296674 -114.186110         0  \n",
       "\n",
       "[1296675 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad7c98b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category',\n",
       "       'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip',\n",
       "       'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time',\n",
       "       'merch_lat', 'merch_long', 'is_fraud'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6f27470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>amt</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "      <td>1.296675e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.483370e+05</td>\n",
       "      <td>4.171920e+17</td>\n",
       "      <td>7.035104e+01</td>\n",
       "      <td>4.880067e+04</td>\n",
       "      <td>3.853762e+01</td>\n",
       "      <td>-9.022634e+01</td>\n",
       "      <td>8.882444e+04</td>\n",
       "      <td>1.349244e+09</td>\n",
       "      <td>3.853734e+01</td>\n",
       "      <td>-9.022646e+01</td>\n",
       "      <td>5.788652e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.743180e+05</td>\n",
       "      <td>1.308806e+18</td>\n",
       "      <td>1.603160e+02</td>\n",
       "      <td>2.689322e+04</td>\n",
       "      <td>5.075808e+00</td>\n",
       "      <td>1.375908e+01</td>\n",
       "      <td>3.019564e+05</td>\n",
       "      <td>1.284128e+07</td>\n",
       "      <td>5.109788e+00</td>\n",
       "      <td>1.377109e+01</td>\n",
       "      <td>7.586269e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.041621e+10</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.257000e+03</td>\n",
       "      <td>2.002710e+01</td>\n",
       "      <td>-1.656723e+02</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>1.325376e+09</td>\n",
       "      <td>1.902779e+01</td>\n",
       "      <td>-1.666712e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.241685e+05</td>\n",
       "      <td>1.800429e+14</td>\n",
       "      <td>9.650000e+00</td>\n",
       "      <td>2.623700e+04</td>\n",
       "      <td>3.462050e+01</td>\n",
       "      <td>-9.679800e+01</td>\n",
       "      <td>7.430000e+02</td>\n",
       "      <td>1.338751e+09</td>\n",
       "      <td>3.473357e+01</td>\n",
       "      <td>-9.689728e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.483370e+05</td>\n",
       "      <td>3.521417e+15</td>\n",
       "      <td>4.752000e+01</td>\n",
       "      <td>4.817400e+04</td>\n",
       "      <td>3.935430e+01</td>\n",
       "      <td>-8.747690e+01</td>\n",
       "      <td>2.456000e+03</td>\n",
       "      <td>1.349250e+09</td>\n",
       "      <td>3.936568e+01</td>\n",
       "      <td>-8.743839e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.725055e+05</td>\n",
       "      <td>4.642255e+15</td>\n",
       "      <td>8.314000e+01</td>\n",
       "      <td>7.204200e+04</td>\n",
       "      <td>4.194040e+01</td>\n",
       "      <td>-8.015800e+01</td>\n",
       "      <td>2.032800e+04</td>\n",
       "      <td>1.359385e+09</td>\n",
       "      <td>4.195716e+01</td>\n",
       "      <td>-8.023680e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.296674e+06</td>\n",
       "      <td>4.992346e+18</td>\n",
       "      <td>2.894890e+04</td>\n",
       "      <td>9.978300e+04</td>\n",
       "      <td>6.669330e+01</td>\n",
       "      <td>-6.795030e+01</td>\n",
       "      <td>2.906700e+06</td>\n",
       "      <td>1.371817e+09</td>\n",
       "      <td>6.751027e+01</td>\n",
       "      <td>-6.695090e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0        cc_num           amt           zip           lat  \\\n",
       "count  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06   \n",
       "mean   6.483370e+05  4.171920e+17  7.035104e+01  4.880067e+04  3.853762e+01   \n",
       "std    3.743180e+05  1.308806e+18  1.603160e+02  2.689322e+04  5.075808e+00   \n",
       "min    0.000000e+00  6.041621e+10  1.000000e+00  1.257000e+03  2.002710e+01   \n",
       "25%    3.241685e+05  1.800429e+14  9.650000e+00  2.623700e+04  3.462050e+01   \n",
       "50%    6.483370e+05  3.521417e+15  4.752000e+01  4.817400e+04  3.935430e+01   \n",
       "75%    9.725055e+05  4.642255e+15  8.314000e+01  7.204200e+04  4.194040e+01   \n",
       "max    1.296674e+06  4.992346e+18  2.894890e+04  9.978300e+04  6.669330e+01   \n",
       "\n",
       "               long      city_pop     unix_time     merch_lat    merch_long  \\\n",
       "count  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06  1.296675e+06   \n",
       "mean  -9.022634e+01  8.882444e+04  1.349244e+09  3.853734e+01 -9.022646e+01   \n",
       "std    1.375908e+01  3.019564e+05  1.284128e+07  5.109788e+00  1.377109e+01   \n",
       "min   -1.656723e+02  2.300000e+01  1.325376e+09  1.902779e+01 -1.666712e+02   \n",
       "25%   -9.679800e+01  7.430000e+02  1.338751e+09  3.473357e+01 -9.689728e+01   \n",
       "50%   -8.747690e+01  2.456000e+03  1.349250e+09  3.936568e+01 -8.743839e+01   \n",
       "75%   -8.015800e+01  2.032800e+04  1.359385e+09  4.195716e+01 -8.023680e+01   \n",
       "max   -6.795030e+01  2.906700e+06  1.371817e+09  6.751027e+01 -6.695090e+01   \n",
       "\n",
       "           is_fraud  \n",
       "count  1.296675e+06  \n",
       "mean   5.788652e-03  \n",
       "std    7.586269e-02  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    1.000000e+00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec94315d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "      <td>1296675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1274791</td>\n",
       "      <td>693</td>\n",
       "      <td>14</td>\n",
       "      <td>352</td>\n",
       "      <td>481</td>\n",
       "      <td>2</td>\n",
       "      <td>983</td>\n",
       "      <td>894</td>\n",
       "      <td>51</td>\n",
       "      <td>494</td>\n",
       "      <td>968</td>\n",
       "      <td>1296675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2019-04-22 16:02:01</td>\n",
       "      <td>fraud_Kilback LLC</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>Christopher</td>\n",
       "      <td>Smith</td>\n",
       "      <td>F</td>\n",
       "      <td>0069 Robin Brooks Apt. 695</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>TX</td>\n",
       "      <td>Film/video editor</td>\n",
       "      <td>1977-03-23</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "      <td>4403</td>\n",
       "      <td>131659</td>\n",
       "      <td>26669</td>\n",
       "      <td>28794</td>\n",
       "      <td>709863</td>\n",
       "      <td>3123</td>\n",
       "      <td>5617</td>\n",
       "      <td>94876</td>\n",
       "      <td>9779</td>\n",
       "      <td>5636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       trans_date_trans_time           merchant       category        first  \\\n",
       "count                1296675            1296675        1296675      1296675   \n",
       "unique               1274791                693             14          352   \n",
       "top      2019-04-22 16:02:01  fraud_Kilback LLC  gas_transport  Christopher   \n",
       "freq                       4               4403         131659        26669   \n",
       "\n",
       "           last   gender                      street        city    state  \\\n",
       "count   1296675  1296675                     1296675     1296675  1296675   \n",
       "unique      481        2                         983         894       51   \n",
       "top       Smith        F  0069 Robin Brooks Apt. 695  Birmingham       TX   \n",
       "freq      28794   709863                        3123        5617    94876   \n",
       "\n",
       "                      job         dob                         trans_num  \n",
       "count             1296675     1296675                           1296675  \n",
       "unique                494         968                           1296675  \n",
       "top     Film/video editor  1977-03-23  0b242abb623afc578575680df30655b9  \n",
       "freq                 9779        5636                                 1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "002450e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data.drop(['Unnamed: 0', 'trans_date_trans_time', 'cc_num','first', 'last','trans_num', 'unix_time','merchant'],axis=1)\n",
    "test_df = pd.read_csv('fraudTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3bfb74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['distance']= (train_df['lat'] - train_df['merch_lat'])**2 + (train_df['long'] - train_df['merch_long'])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b973f56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['merch_lat', 'merch_long','lat', 'long'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "152bbec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Function to calculate age\n",
    "def calculate_age(dob):\n",
    "    today = datetime.today()\n",
    "    dob = datetime.strptime(dob, '%Y-%m-%d')\n",
    "    age = today.year - dob.year - ((today.month, today.day) < (dob.month, dob.day))\n",
    "    return age\n",
    "\n",
    "# Apply the function to the 'dob' column\n",
    "train_df['age'] = train_df['dob'].apply(calculate_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "210cafd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['dob'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fff694bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['street','zip','city_pop'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e85e852e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'amt', 'gender', 'city', 'state', 'job', 'is_fraud',\n",
       "       'distance', 'age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dafbcc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['category', 'gender', 'job','city','state']\n",
    "for column in categorical_columns:\n",
    "    train_df[column] = train_df[column].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9af53317",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ea8779c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"train_df.csv\")\n",
    "train_df.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b6e6db37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category     object\n",
       "amt         float64\n",
       "gender       object\n",
       "city         object\n",
       "state        object\n",
       "job          object\n",
       "is_fraud      int64\n",
       "distance    float64\n",
       "age           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "61fcafcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all object columns to category\n",
    "train_df = train_df.apply(lambda col: col.astype('category') if col.dtype == 'object' else col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a84a5a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "X = train_df.drop(['is_fraud'], axis=1)\n",
    "y = train_df['is_fraud']\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d5e5415e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257815\n",
      "           1       0.81      0.65      0.72      1520\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.90      0.83      0.86    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n",
      "confusion_matrix \n",
      " [[257582    233]\n",
      " [   530    990]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "model = xgb.XGBClassifier(random_state=42,enable_categorical=True)#,scale_pos_weight=scale_pos_weight)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "\n",
    "print(f\"classification report \\n {classification_report(y_val, y_val_pred)}\")\n",
    "print(f\"confusion_matrix \\n {confusion_matrix(y_val, y_val_pred)}\")\n",
    "\n",
    "xgb.plot_importance(model)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7504f99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_fraud\n",
       "0    1031354\n",
       "1       5986\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bfb622d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.97365\n",
      "[1]\tvalidation_0-auc:0.97962\n",
      "[2]\tvalidation_0-auc:0.98000\n",
      "[3]\tvalidation_0-auc:0.98307\n",
      "[4]\tvalidation_0-auc:0.98576\n",
      "[5]\tvalidation_0-auc:0.98815\n",
      "[6]\tvalidation_0-auc:0.98819\n",
      "[7]\tvalidation_0-auc:0.98702\n",
      "[8]\tvalidation_0-auc:0.98755\n",
      "[9]\tvalidation_0-auc:0.98708\n",
      "[10]\tvalidation_0-auc:0.98710\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99    257815\n",
      "           1       0.16      0.92      0.27      1520\n",
      "\n",
      "    accuracy                           0.97    259335\n",
      "   macro avg       0.58      0.95      0.63    259335\n",
      "weighted avg       0.99      0.97      0.98    259335\n",
      "\n",
      "confusion_matrix \n",
      " [[250407   7408]\n",
      " [   123   1397]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "model = xgb.XGBClassifier(early_stopping_rounds =5 ,eval_metric='auc', random_state=42,enable_categorical=True,scale_pos_weight=scale_pos_weight)\n",
    "model.fit(X_train, y_train,eval_set=[(X_val, y_val)])\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "\n",
    "print(f\"classification report \\n {classification_report(y_val, y_val_pred)}\")\n",
    "print(f\"confusion_matrix \\n {confusion_matrix(y_val, y_val_pred)}\")\n",
    "\n",
    "xgb.plot_importance(model)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca42c0c5",
   "metadata": {},
   "source": [
    "##### Use stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f1ffb150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "base_learners = [\n",
    "    ('lgbm',lgbm.LGBMClassifier(random_state=42)),\n",
    "    ('xgb', xgb.XGBClassifier(random_state=42, enable_categorical=True))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7a6cb7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 5986, number of negative: 1031354\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1918\n",
      "[LightGBM] [Info] Number of data points in the train set: 1037340, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.005771 -> initscore=-5.149204\n",
      "[LightGBM] [Info] Start training from score -5.149204\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 4789, number of negative: 825083\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1920\n",
      "[LightGBM] [Info] Number of data points in the train set: 829872, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.005771 -> initscore=-5.149162\n",
      "[LightGBM] [Info] Start training from score -5.149162\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 4789, number of negative: 825083\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1919\n",
      "[LightGBM] [Info] Number of data points in the train set: 829872, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.005771 -> initscore=-5.149162\n",
      "[LightGBM] [Info] Start training from score -5.149162\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 4789, number of negative: 825083\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.143484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1921\n",
      "[LightGBM] [Info] Number of data points in the train set: 829872, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.005771 -> initscore=-5.149162\n",
      "[LightGBM] [Info] Start training from score -5.149162\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 4789, number of negative: 825083\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1920\n",
      "[LightGBM] [Info] Number of data points in the train set: 829872, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.005771 -> initscore=-5.149162\n",
      "[LightGBM] [Info] Start training from score -5.149162\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 4788, number of negative: 825084\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1919\n",
      "[LightGBM] [Info] Number of data points in the train set: 829872, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.005770 -> initscore=-5.149372\n",
      "[LightGBM] [Info] Start training from score -5.149372\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;, LGBMClassifier(random_state=42)),\n",
       "                               (&#x27;xgb&#x27;,\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=True,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=42, ...))],\n",
       "                   final_estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StackingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.StackingClassifier.html\">?<span>Documentation for StackingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;, LGBMClassifier(random_state=42)),\n",
       "                               (&#x27;xgb&#x27;,\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=True,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=42, ...))],\n",
       "                   final_estimator=LogisticRegression())</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(estimators=[('lgbm', LGBMClassifier(random_state=42)),\n",
       "                               ('xgb',\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=True,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_threshold=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=None, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=42, ...))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_learner = LogisticRegression()\n",
    "\n",
    "stacking_model = StackingClassifier(estimators=base_learners, final_estimator=meta_learner)\n",
    "\n",
    "stacking_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "97d74d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257815\n",
      "           1       0.85      0.61      0.71      1520\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.92      0.81      0.85    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n",
      "confusion_matrix \n",
      " [[257650    165]\n",
      " [   591    929]]\n"
     ]
    }
   ],
   "source": [
    "#model = xgb.XGBClassifier(early_stopping_rounds=10, eval_metric='auc',enable_categorical=True)\n",
    "#model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=True)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = stacking_model.predict(X_val)\n",
    "\n",
    "print(f\"classification report \\n {classification_report(y_val, y_val_pred)}\")\n",
    "print(f\"confusion_matrix \\n {confusion_matrix(y_val, y_val_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0e6d5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb.plot_tree(model, num_trees=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc2e91",
   "metadata": {},
   "source": [
    "#### Neural nets approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "359ba4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9d894562",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train_df,drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1f3a535b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amt</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>distance</th>\n",
       "      <th>age</th>\n",
       "      <th>category_food_dining</th>\n",
       "      <th>category_gas_transport</th>\n",
       "      <th>category_grocery_net</th>\n",
       "      <th>category_grocery_pos</th>\n",
       "      <th>category_health_fitness</th>\n",
       "      <th>category_home</th>\n",
       "      <th>...</th>\n",
       "      <th>job_Visual merchandiser</th>\n",
       "      <th>job_Volunteer coordinator</th>\n",
       "      <th>job_Warden/ranger</th>\n",
       "      <th>job_Warehouse manager</th>\n",
       "      <th>job_Waste management officer</th>\n",
       "      <th>job_Water engineer</th>\n",
       "      <th>job_Water quality scientist</th>\n",
       "      <th>job_Web designer</th>\n",
       "      <th>job_Wellsite geologist</th>\n",
       "      <th>job_Writer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0.761831</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074153</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.952274</td>\n",
       "      <td>62</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.846035</td>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0.754300</td>\n",
       "      <td>38</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296670</th>\n",
       "      <td>15.56</td>\n",
       "      <td>0</td>\n",
       "      <td>1.387053</td>\n",
       "      <td>62</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296671</th>\n",
       "      <td>51.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671796</td>\n",
       "      <td>44</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296672</th>\n",
       "      <td>105.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.936136</td>\n",
       "      <td>57</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296673</th>\n",
       "      <td>74.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.807797</td>\n",
       "      <td>44</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296674</th>\n",
       "      <td>4.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.619185</td>\n",
       "      <td>29</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1296675 rows Ã— 1454 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            amt  is_fraud  distance  age  category_food_dining  \\\n",
       "0          4.97         0  0.761831   36                 False   \n",
       "1        107.23         0  0.074153   46                 False   \n",
       "2        220.11         0  0.952274   62                 False   \n",
       "3         45.00         0  0.846035   57                 False   \n",
       "4         41.96         0  0.754300   38                 False   \n",
       "...         ...       ...       ...  ...                   ...   \n",
       "1296670   15.56         0  1.387053   62                 False   \n",
       "1296671   51.70         0  0.671796   44                  True   \n",
       "1296672  105.93         0  0.936136   57                  True   \n",
       "1296673   74.90         0  0.807797   44                  True   \n",
       "1296674    4.30         0  0.619185   29                  True   \n",
       "\n",
       "         category_gas_transport  category_grocery_net  category_grocery_pos  \\\n",
       "0                         False                 False                 False   \n",
       "1                         False                 False                  True   \n",
       "2                         False                 False                 False   \n",
       "3                          True                 False                 False   \n",
       "4                         False                 False                 False   \n",
       "...                         ...                   ...                   ...   \n",
       "1296670                   False                 False                 False   \n",
       "1296671                   False                 False                 False   \n",
       "1296672                   False                 False                 False   \n",
       "1296673                   False                 False                 False   \n",
       "1296674                   False                 False                 False   \n",
       "\n",
       "         category_health_fitness  category_home  ...  job_Visual merchandiser  \\\n",
       "0                          False          False  ...                    False   \n",
       "1                          False          False  ...                    False   \n",
       "2                          False          False  ...                    False   \n",
       "3                          False          False  ...                    False   \n",
       "4                          False          False  ...                    False   \n",
       "...                          ...            ...  ...                      ...   \n",
       "1296670                    False          False  ...                    False   \n",
       "1296671                    False          False  ...                    False   \n",
       "1296672                    False          False  ...                    False   \n",
       "1296673                    False          False  ...                    False   \n",
       "1296674                    False          False  ...                    False   \n",
       "\n",
       "         job_Volunteer coordinator  job_Warden/ranger  job_Warehouse manager  \\\n",
       "0                            False              False                  False   \n",
       "1                            False              False                  False   \n",
       "2                            False              False                  False   \n",
       "3                            False              False                  False   \n",
       "4                            False              False                  False   \n",
       "...                            ...                ...                    ...   \n",
       "1296670                      False              False                  False   \n",
       "1296671                      False              False                  False   \n",
       "1296672                      False              False                  False   \n",
       "1296673                       True              False                  False   \n",
       "1296674                      False              False                  False   \n",
       "\n",
       "         job_Waste management officer  job_Water engineer  \\\n",
       "0                               False               False   \n",
       "1                               False               False   \n",
       "2                               False               False   \n",
       "3                               False               False   \n",
       "4                               False               False   \n",
       "...                               ...                 ...   \n",
       "1296670                         False               False   \n",
       "1296671                         False               False   \n",
       "1296672                         False               False   \n",
       "1296673                         False               False   \n",
       "1296674                         False               False   \n",
       "\n",
       "         job_Water quality scientist  job_Web designer  \\\n",
       "0                              False             False   \n",
       "1                              False             False   \n",
       "2                              False             False   \n",
       "3                              False             False   \n",
       "4                              False             False   \n",
       "...                              ...               ...   \n",
       "1296670                        False             False   \n",
       "1296671                        False             False   \n",
       "1296672                        False             False   \n",
       "1296673                        False             False   \n",
       "1296674                        False             False   \n",
       "\n",
       "         job_Wellsite geologist  job_Writer  \n",
       "0                         False       False  \n",
       "1                         False       False  \n",
       "2                         False       False  \n",
       "3                         False       False  \n",
       "4                         False       False  \n",
       "...                         ...         ...  \n",
       "1296670                   False       False  \n",
       "1296671                   False       False  \n",
       "1296672                   False       False  \n",
       "1296673                   False       False  \n",
       "1296674                   False       False  \n",
       "\n",
       "[1296675 rows x 1454 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "000ab270",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "numerical_columns = ['amt', 'age','distance']\n",
    "train_df[numerical_columns] = scaler.fit_transform(train_df[numerical_columns])\n",
    "#test_df[numerical_columns] = scaler.transform(test_df[numerical_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ac632225",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.apply(lambda x: x.astype(int) if x.dtype == bool else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f403d302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized class weights: is_fraud\n",
      "0      1.000000\n",
      "1    172.294353\n",
      "Name: count, dtype: float64\n",
      "330201     1.0\n",
      "798518     1.0\n",
      "1260375    1.0\n",
      "412511     1.0\n",
      "344644     1.0\n",
      "          ... \n",
      "110268     1.0\n",
      "259178     1.0\n",
      "131932     1.0\n",
      "671155     1.0\n",
      "121958     1.0\n",
      "Name: is_fraud, Length: 1037340, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_df.drop('is_fraud', axis=1), train_df['is_fraud'], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "# Calculate class weights\n",
    "class_counts = y_train.value_counts()\n",
    "class_weights = 1. / class_counts\n",
    "\n",
    "class_weights_normalized = class_weights / class_weights.min()\n",
    "print(f\"Normalized class weights: {class_weights_normalized}\")\n",
    "\n",
    "sample_weights = y_train.map(class_weights_normalized)\n",
    "print(sample_weights)\n",
    "sample_weights = torch.tensor(sample_weights.values, dtype=torch.float32)\n",
    "train_sampler = torch.utils.data.WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "\n",
    "# Update DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64  , sampler=train_sampler)\n",
    "\n",
    "#train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "61919350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos weight :tensor([172.2944])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class WeightedBCELoss(nn.Module):\n",
    "    def __init__(self, pos_weight):\n",
    "        super(WeightedBCELoss, self).__init__()\n",
    "        self.pos_weight = max(pos_weight,1)#-math.inf)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        loss = nn.functional.binary_cross_entropy_with_logits(inputs, targets, pos_weight=self.pos_weight)\n",
    "        return loss\n",
    "\n",
    "pos_weight = torch.tensor([len(y_train[y_train == 0]) / len(y_train[y_train == 1])])\n",
    "print(f\"pos weight :{pos_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3a4ae02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(loader):\n",
    "    model.eval()   \n",
    "\n",
    "    correct = 0  # the number of correct predictions.\n",
    "    total = 0  # the total number of predictions.\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for inputs, targets in loader:  \n",
    "           # inputs, targets = inputs.to(device), targets.to(device)  \n",
    "\n",
    "            outputs = model(inputs) \n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)  \n",
    "\n",
    "            total += targets.size(0)  \n",
    "            # Calculate the number of correct predictions in the batch by comparing predicted with targets, summing the true predictions, and adding this sum to the correct counter.\n",
    "            correct += (predicted == targets).sum().item()  \n",
    "\n",
    "    return 100 * correct / total  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ec225550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 1.3165, Val Loss: 1.1814 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.28      0.44   1031354\n",
      "         1.0       0.01      0.72      0.01      5986\n",
      "\n",
      "    accuracy                           0.29   1037340\n",
      "   macro avg       0.50      0.50      0.23   1037340\n",
      "weighted avg       0.99      0.29      0.44   1037340\n",
      "\n",
      "[[292824 738530]\n",
      " [  1670   4316]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.75      0.86    257815\n",
      "         1.0       0.02      0.96      0.04      1520\n",
      "\n",
      "    accuracy                           0.75    259335\n",
      "   macro avg       0.51      0.85      0.45    259335\n",
      "weighted avg       0.99      0.75      0.85    259335\n",
      "\n",
      "[[193258  64557]\n",
      " [    63   1457]]\n",
      "Epoch 2/20, Train Loss: 0.7162, Val Loss: 0.8896 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.38      0.55   1031354\n",
      "         1.0       0.01      0.63      0.01      5986\n",
      "\n",
      "    accuracy                           0.38   1037340\n",
      "   macro avg       0.50      0.50      0.28   1037340\n",
      "weighted avg       0.99      0.38      0.54   1037340\n",
      "\n",
      "[[388794 642560]\n",
      " [  2232   3754]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.86      0.93    257815\n",
      "         1.0       0.04      0.92      0.07      1520\n",
      "\n",
      "    accuracy                           0.86    259335\n",
      "   macro avg       0.52      0.89      0.50    259335\n",
      "weighted avg       0.99      0.86      0.92    259335\n",
      "\n",
      "[[221984  35831]\n",
      " [   127   1393]]\n",
      "Epoch 3/20, Train Loss: 0.6227, Val Loss: 0.8321 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.40      0.57   1031354\n",
      "         1.0       0.01      0.59      0.01      5986\n",
      "\n",
      "    accuracy                           0.40   1037340\n",
      "   macro avg       0.50      0.50      0.29   1037340\n",
      "weighted avg       0.99      0.40      0.57   1037340\n",
      "\n",
      "[[410951 620403]\n",
      " [  2427   3559]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.88      0.94    257815\n",
      "         1.0       0.04      0.91      0.08      1520\n",
      "\n",
      "    accuracy                           0.88    259335\n",
      "   macro avg       0.52      0.89      0.51    259335\n",
      "weighted avg       0.99      0.88      0.93    259335\n",
      "\n",
      "[[227222  30593]\n",
      " [   140   1380]]\n",
      "Epoch 4/20, Train Loss: 0.5905, Val Loss: 0.7944 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.41      0.58   1031354\n",
      "         1.0       0.01      0.60      0.01      5986\n",
      "\n",
      "    accuracy                           0.41   1037340\n",
      "   macro avg       0.50      0.50      0.29   1037340\n",
      "weighted avg       0.99      0.41      0.57   1037340\n",
      "\n",
      "[[418320 613034]\n",
      " [  2372   3614]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.90      0.94    257815\n",
      "         1.0       0.05      0.90      0.09      1520\n",
      "\n",
      "    accuracy                           0.90    259335\n",
      "   macro avg       0.52      0.90      0.52    259335\n",
      "weighted avg       0.99      0.90      0.94    259335\n",
      "\n",
      "[[230997  26818]\n",
      " [   146   1374]]\n",
      "Epoch 5/20, Train Loss: 0.5725, Val Loss: 0.8209 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.41      0.58   1031354\n",
      "         1.0       0.01      0.60      0.01      5986\n",
      "\n",
      "    accuracy                           0.41   1037340\n",
      "   macro avg       0.50      0.50      0.30   1037340\n",
      "weighted avg       0.99      0.41      0.58   1037340\n",
      "\n",
      "[[422669 608685]\n",
      " [  2423   3563]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.89      0.94    257815\n",
      "         1.0       0.05      0.91      0.09      1520\n",
      "\n",
      "    accuracy                           0.89    259335\n",
      "   macro avg       0.52      0.90      0.52    259335\n",
      "weighted avg       0.99      0.89      0.94    259335\n",
      "\n",
      "[[230436  27379]\n",
      " [   133   1387]]\n",
      "Epoch 6/20, Train Loss: 0.5699, Val Loss: 0.8067 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.41      0.58   1031354\n",
      "         1.0       0.01      0.58      0.01      5986\n",
      "\n",
      "    accuracy                           0.41   1037340\n",
      "   macro avg       0.50      0.50      0.30   1037340\n",
      "weighted avg       0.99      0.41      0.58   1037340\n",
      "\n",
      "[[424324 607030]\n",
      " [  2494   3492]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.90      0.95    257815\n",
      "         1.0       0.05      0.90      0.09      1520\n",
      "\n",
      "    accuracy                           0.90    259335\n",
      "   macro avg       0.52      0.90      0.52    259335\n",
      "weighted avg       0.99      0.90      0.94    259335\n",
      "\n",
      "[[231716  26099]\n",
      " [   146   1374]]\n",
      "Epoch 7/20, Train Loss: 0.5509, Val Loss: 0.7518 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.41      0.58   1031354\n",
      "         1.0       0.01      0.59      0.01      5986\n",
      "\n",
      "    accuracy                           0.42   1037340\n",
      "   macro avg       0.50      0.50      0.30   1037340\n",
      "weighted avg       0.99      0.42      0.58   1037340\n",
      "\n",
      "[[427067 604287]\n",
      " [  2476   3510]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.91      0.95    257815\n",
      "         1.0       0.06      0.90      0.10      1520\n",
      "\n",
      "    accuracy                           0.91    259335\n",
      "   macro avg       0.53      0.90      0.53    259335\n",
      "weighted avg       0.99      0.91      0.95    259335\n",
      "\n",
      "[[234501  23314]\n",
      " [   157   1363]]\n",
      "Epoch 8/20, Train Loss: 0.5527, Val Loss: 0.7814 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.42      0.59   1031354\n",
      "         1.0       0.01      0.59      0.01      5986\n",
      "\n",
      "    accuracy                           0.42   1037340\n",
      "   macro avg       0.50      0.50      0.30   1037340\n",
      "weighted avg       0.99      0.42      0.58   1037340\n",
      "\n",
      "[[428236 603118]\n",
      " [  2426   3560]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.90      0.95    257815\n",
      "         1.0       0.05      0.91      0.10      1520\n",
      "\n",
      "    accuracy                           0.90    259335\n",
      "   macro avg       0.53      0.91      0.52    259335\n",
      "weighted avg       0.99      0.90      0.94    259335\n",
      "\n",
      "[[232944  24871]\n",
      " [   137   1383]]\n",
      "Epoch 9/20, Train Loss: 0.5488, Val Loss: 0.7887 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.41      0.58   1031354\n",
      "         1.0       0.01      0.58      0.01      5986\n",
      "\n",
      "    accuracy                           0.41   1037340\n",
      "   macro avg       0.50      0.49      0.30   1037340\n",
      "weighted avg       0.99      0.41      0.58   1037340\n",
      "\n",
      "[[426817 604537]\n",
      " [  2538   3448]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.90      0.95    257815\n",
      "         1.0       0.05      0.91      0.10      1520\n",
      "\n",
      "    accuracy                           0.90    259335\n",
      "   macro avg       0.53      0.91      0.52    259335\n",
      "weighted avg       0.99      0.90      0.94    259335\n",
      "\n",
      "[[232303  25512]\n",
      " [   132   1388]]\n",
      "Epoch 10/20, Train Loss: 0.5436, Val Loss: 0.7270 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.42      0.59   1031354\n",
      "         1.0       0.01      0.57      0.01      5986\n",
      "\n",
      "    accuracy                           0.42   1037340\n",
      "   macro avg       0.50      0.49      0.30   1037340\n",
      "weighted avg       0.99      0.42      0.58   1037340\n",
      "\n",
      "[[429891 601463]\n",
      " [  2582   3404]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.93      0.96    257815\n",
      "         1.0       0.07      0.90      0.13      1520\n",
      "\n",
      "    accuracy                           0.93    259335\n",
      "   macro avg       0.53      0.91      0.54    259335\n",
      "weighted avg       0.99      0.93      0.96    259335\n",
      "\n",
      "[[239129  18686]\n",
      " [   156   1364]]\n",
      "Epoch 11/20, Train Loss: 0.5449, Val Loss: 0.7545 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.42      0.59   1031354\n",
      "         1.0       0.01      0.58      0.01      5986\n",
      "\n",
      "    accuracy                           0.42   1037340\n",
      "   macro avg       0.50      0.50      0.30   1037340\n",
      "weighted avg       0.99      0.42      0.58   1037340\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[429282 602072]\n",
      " [  2525   3461]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.91      0.95    257815\n",
      "         1.0       0.06      0.91      0.11      1520\n",
      "\n",
      "    accuracy                           0.91    259335\n",
      "   macro avg       0.53      0.91      0.53    259335\n",
      "weighted avg       0.99      0.91      0.95    259335\n",
      "\n",
      "[[234400  23415]\n",
      " [   137   1383]]\n",
      "Epoch 12/20, Train Loss: 0.5491, Val Loss: 0.6507 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.42      0.59   1031354\n",
      "         1.0       0.01      0.59      0.01      5986\n",
      "\n",
      "    accuracy                           0.42   1037340\n",
      "   macro avg       0.50      0.50      0.30   1037340\n",
      "weighted avg       0.99      0.42      0.58   1037340\n",
      "\n",
      "[[429159 602195]\n",
      " [  2454   3532]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.93      0.96    257815\n",
      "         1.0       0.07      0.88      0.12      1520\n",
      "\n",
      "    accuracy                           0.93    259335\n",
      "   macro avg       0.53      0.91      0.54    259335\n",
      "weighted avg       0.99      0.93      0.96    259335\n",
      "\n",
      "[[239186  18629]\n",
      " [   177   1343]]\n",
      "Epoch 13/20, Train Loss: 0.5303, Val Loss: 0.7159 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.42      0.59   1031354\n",
      "         1.0       0.01      0.59      0.01      5986\n",
      "\n",
      "    accuracy                           0.42   1037340\n",
      "   macro avg       0.50      0.50      0.30   1037340\n",
      "weighted avg       0.99      0.42      0.59   1037340\n",
      "\n",
      "[[431362 599992]\n",
      " [  2479   3507]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.93      0.97    257815\n",
      "         1.0       0.07      0.90      0.14      1520\n",
      "\n",
      "    accuracy                           0.93    259335\n",
      "   macro avg       0.54      0.92      0.55    259335\n",
      "weighted avg       0.99      0.93      0.96    259335\n",
      "\n",
      "[[240879  16936]\n",
      " [   155   1365]]\n",
      "Epoch 14/20, Train Loss: 0.5372, Val Loss: 0.7265 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.42      0.59   1031354\n",
      "         1.0       0.01      0.59      0.01      5986\n",
      "\n",
      "    accuracy                           0.42   1037340\n",
      "   macro avg       0.50      0.51      0.30   1037340\n",
      "weighted avg       0.99      0.42      0.59   1037340\n",
      "\n",
      "[[430996 600358]\n",
      " [  2438   3548]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.92      0.96    257815\n",
      "         1.0       0.06      0.91      0.12      1520\n",
      "\n",
      "    accuracy                           0.92    259335\n",
      "   macro avg       0.53      0.92      0.54    259335\n",
      "weighted avg       0.99      0.92      0.95    259335\n",
      "\n",
      "[[237599  20216]\n",
      " [   136   1384]]\n",
      "Epoch 15/20, Train Loss: 0.5405, Val Loss: 1.3075 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.42      0.59   1031354\n",
      "         1.0       0.01      0.58      0.01      5986\n",
      "\n",
      "    accuracy                           0.42   1037340\n",
      "   macro avg       0.50      0.50      0.30   1037340\n",
      "weighted avg       0.99      0.42      0.58   1037340\n",
      "\n",
      "[[430302 601052]\n",
      " [  2540   3446]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.79      0.88    257815\n",
      "         1.0       0.02      0.83      0.04      1520\n",
      "\n",
      "    accuracy                           0.79    259335\n",
      "   macro avg       0.51      0.81      0.46    259335\n",
      "weighted avg       0.99      0.79      0.88    259335\n",
      "\n",
      "[[203821  53994]\n",
      " [   262   1258]]\n",
      "Epoch 16/20, Train Loss: 0.5432, Val Loss: 0.6846 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.42      0.59   1031354\n",
      "         1.0       0.01      0.60      0.01      5986\n",
      "\n",
      "    accuracy                           0.42   1037340\n",
      "   macro avg       0.50      0.51      0.30   1037340\n",
      "weighted avg       0.99      0.42      0.58   1037340\n",
      "\n",
      "[[429475 601879]\n",
      " [  2390   3596]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.93      0.96    257815\n",
      "         1.0       0.07      0.88      0.13      1520\n",
      "\n",
      "    accuracy                           0.93    259335\n",
      "   macro avg       0.53      0.91      0.54    259335\n",
      "weighted avg       0.99      0.93      0.96    259335\n",
      "\n",
      "[[239421  18394]\n",
      " [   180   1340]]\n",
      "Epoch 17/20, Train Loss: 0.5487, Val Loss: 0.7005 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.42      0.59   1031354\n",
      "         1.0       0.01      0.58      0.01      5986\n",
      "\n",
      "    accuracy                           0.42   1037340\n",
      "   macro avg       0.50      0.50      0.30   1037340\n",
      "weighted avg       0.99      0.42      0.58   1037340\n",
      "\n",
      "[[429538 601816]\n",
      " [  2494   3492]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.92      0.96    257815\n",
      "         1.0       0.06      0.91      0.11      1520\n",
      "\n",
      "    accuracy                           0.92    259335\n",
      "   macro avg       0.53      0.91      0.53    259335\n",
      "weighted avg       0.99      0.92      0.95    259335\n",
      "\n",
      "[[236072  21743]\n",
      " [   140   1380]]\n",
      "Epoch 18/20, Train Loss: 0.5469, Val Loss: 0.6973 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.42      0.59   1031354\n",
      "         1.0       0.01      0.59      0.01      5986\n",
      "\n",
      "    accuracy                           0.42   1037340\n",
      "   macro avg       0.50      0.50      0.30   1037340\n",
      "weighted avg       0.99      0.42      0.58   1037340\n",
      "\n",
      "[[430034 601320]\n",
      " [  2477   3509]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.93      0.96    257815\n",
      "         1.0       0.07      0.91      0.13      1520\n",
      "\n",
      "    accuracy                           0.93    259335\n",
      "   macro avg       0.53      0.92      0.54    259335\n",
      "weighted avg       0.99      0.93      0.96    259335\n",
      "\n",
      "[[238679  19136]\n",
      " [   142   1378]]\n",
      "Epoch 19/20, Train Loss: 0.5471, Val Loss: 0.6781 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.42      0.59   1031354\n",
      "         1.0       0.01      0.58      0.01      5986\n",
      "\n",
      "    accuracy                           0.42   1037340\n",
      "   macro avg       0.50      0.50      0.30   1037340\n",
      "weighted avg       0.99      0.42      0.58   1037340\n",
      "\n",
      "[[430475 600879]\n",
      " [  2512   3474]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.94      0.97    257815\n",
      "         1.0       0.08      0.90      0.14      1520\n",
      "\n",
      "    accuracy                           0.93    259335\n",
      "   macro avg       0.54      0.92      0.55    259335\n",
      "weighted avg       0.99      0.93      0.96    259335\n",
      "\n",
      "[[241073  16742]\n",
      " [   156   1364]]\n",
      "Epoch 20/20, Train Loss: 0.5395, Val Loss: 0.6508 \n",
      "training \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.42      0.59   1031354\n",
      "         1.0       0.01      0.58      0.01      5986\n",
      "\n",
      "    accuracy                           0.42   1037340\n",
      "   macro avg       0.50      0.50      0.30   1037340\n",
      "weighted avg       0.99      0.42      0.58   1037340\n",
      "\n",
      "[[430838 600516]\n",
      " [  2540   3446]]\n",
      "Validation \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.93      0.96    257815\n",
      "         1.0       0.07      0.90      0.13      1520\n",
      "\n",
      "    accuracy                           0.93    259335\n",
      "   macro avg       0.53      0.92      0.55    259335\n",
      "weighted avg       0.99      0.93      0.96    259335\n",
      "\n",
      "[[239542  18273]\n",
      " [   145   1375]]\n",
      "Model training complete and saved as fraud_detection_nn.pth\n"
     ]
    }
   ],
   "source": [
    "class FraudDetectionNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FraudDetectionNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train.shape[1], 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        #x = torch.sigmoid(self.fc3(x))\n",
    "        x = self.fc3(x)   # using bweighted BCE with logits \n",
    "        return x\n",
    "\n",
    "\n",
    "model = FraudDetectionNN()\n",
    "#criterion = nn.BCELoss()\n",
    "criterion = WeightedBCELoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    y_train_pred = []\n",
    "    y_val_pred=[]\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "        y_train_pred.extend(outputs.detach().numpy())\n",
    "\n",
    "    y_train_pred = np.array(y_train_pred)\n",
    "    y_train_pred = (y_train_pred >= 0.5).astype(int)\n",
    "\n",
    "    y_train_true = y_train_tensor.numpy()\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "            y_val_pred.extend(outputs.detach().numpy())\n",
    "\n",
    "    y_val_pred = np.array(y_val_pred)\n",
    "    y_val_pred = (y_val_pred >= 0.5).astype(int)\n",
    "\n",
    "    y_val_true = y_val_tensor.cpu().numpy()\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "   #train_accuracy = calculate_accuracy(train_loader)\n",
    "   #l_accuracy = calculate_accuracy(val_loader)\n",
    " \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f} ')#in Accuracy: {train_accuracy:.2f}%, Test Accuracy: {val_accuracy:.2f}%')\n",
    "    print(f\"training \\n {classification_report(y_train_true, y_train_pred)}\")\n",
    "    print(confusion_matrix(y_train_true, y_train_pred)) \n",
    "    print(f\"Validation \\n {classification_report(y_val_true, y_val_pred)}\")\n",
    "    print(confusion_matrix(y_val_true, y_val_pred)) \n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'fraud_detection_nn.pth')\n",
    "\n",
    "print(\"Model training complete and saved as fraud_detection_nn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b9a11c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebe07a3",
   "metadata": {},
   "source": [
    "Model confusion matrix andclassification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dc0ee897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 1.3707, Val Loss: 1.0454\n",
      "Epoch 2/20, Train Loss: 0.7341, Val Loss: 0.9645\n",
      "Epoch 3/20, Train Loss: 0.6357, Val Loss: 0.8091\n",
      "Epoch 4/20, Train Loss: 0.6009, Val Loss: 0.7213\n",
      "Epoch 5/20, Train Loss: 0.5738, Val Loss: 0.7852\n",
      "Epoch 6/20, Train Loss: 0.5744, Val Loss: 0.7089\n",
      "Epoch 7/20, Train Loss: 0.5654, Val Loss: 0.7669\n",
      "Epoch 8/20, Train Loss: 0.5624, Val Loss: 0.7209\n",
      "Epoch 9/20, Train Loss: 0.5617, Val Loss: 0.7295\n",
      "Epoch 10/20, Train Loss: 0.5606, Val Loss: 0.7949\n",
      "Epoch 11/20, Train Loss: 0.5639, Val Loss: 0.7328\n",
      "Early stopping\n",
      "Model training complete and saved as fraud_detection_nn_es.pth\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, optimizer, and early stopping\n",
    "model = FraudDetectionNN()\n",
    "#criterion = nn.BCELoss\n",
    "criterion = WeightedBCELoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.003)\n",
    "\n",
    "# Training loop with early stopping\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    # Check early stopping condition\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'fraud_detection_nn_es.pth')\n",
    "print(\"Model training complete and saved as fraud_detection_nn_es.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d06c9",
   "metadata": {},
   "source": [
    "####### \n",
    "Epoch 1/20, Train Loss: 0.0278, Val Loss: 0.0203\n",
    "Epoch 2/20, Train Loss: 0.0217, Val Loss: 0.0203\n",
    "Epoch 3/20, Train Loss: 0.0225, Val Loss: 0.0216\n",
    "Epoch 4/20, Train Loss: 0.0217, Val Loss: 0.0246\n",
    "Epoch 5/20, Train Loss: 0.0199, Val Loss: 0.0183\n",
    "Epoch 6/20, Train Loss: 0.0194, Val Loss: 0.0152\n",
    "Epoch 7/20, Train Loss: 0.0189, Val Loss: 0.0169\n",
    "Epoch 8/20, Train Loss: 0.0182, Val Loss: 0.0141\n",
    "Epoch 9/20, Train Loss: 0.0185, Val Loss: 0.0271\n",
    "Epoch 10/20, Train Loss: 0.0185, Val Loss: 0.0175\n",
    "Epoch 11/20, Train Loss: 0.0187, Val Loss: 0.0139\n",
    "Epoch 12/20, Train Loss: 0.0180, Val Loss: 0.0171\n",
    "Epoch 13/20, Train Loss: 0.0176, Val Loss: 0.0132\n",
    "Epoch 14/20, Train Loss: 0.0170, Val Loss: 0.0134\n",
    "Epoch 15/20, Train Loss: 0.0167, Val Loss: 0.0151\n",
    "Epoch 16/20, Train Loss: 0.0165, Val Loss: 0.0144\n",
    "Epoch 17/20, Train Loss: 0.0162, Val Loss: 0.0134\n",
    "Epoch 18/20, Train Loss: 0.0160, Val Loss: 0.0122\n",
    "Epoch 19/20, Train Loss: 0.0159, Val Loss: 0.0135\n",
    "Epoch 20/20, Train Loss: 0.0157, Val Loss: 0.0122\n",
    "Model training complete and saved as fraud_detection_nn.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "490ddef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('fraudTest.csv')\n",
    "test_df = test_df.drop(['street','zip','city_pop','Unnamed: 0', 'trans_date_trans_time', 'cc_num','first', 'last','trans_num', 'unix_time','merchant'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6069b274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b09e476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['distance']= (test_df['lat'] - test_df['merch_lat'])**2 + (test_df['long'] - test_df['merch_long'])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "51ef64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(['merch_lat', 'merch_long','lat', 'long'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "278fbc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['age'] = test_df['dob'].apply(calculate_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d7383c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(['dob'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0065ee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.get_dummies(test_df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "28a32247",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['amt', 'age','distance']\n",
    "test_df[numerical_columns] = scaler.transform(test_df[numerical_columns])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0ed599c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=test_df.apply(lambda x: x.astype(int) if x.dtype==bool else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dbd5bfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amt</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>distance</th>\n",
       "      <th>age</th>\n",
       "      <th>category_food_dining</th>\n",
       "      <th>category_gas_transport</th>\n",
       "      <th>category_grocery_net</th>\n",
       "      <th>category_grocery_pos</th>\n",
       "      <th>category_health_fitness</th>\n",
       "      <th>category_home</th>\n",
       "      <th>...</th>\n",
       "      <th>job_Visual merchandiser</th>\n",
       "      <th>job_Volunteer coordinator</th>\n",
       "      <th>job_Warden/ranger</th>\n",
       "      <th>job_Warehouse manager</th>\n",
       "      <th>job_Waste management officer</th>\n",
       "      <th>job_Water engineer</th>\n",
       "      <th>job_Water quality scientist</th>\n",
       "      <th>job_Web designer</th>\n",
       "      <th>job_Wellsite geologist</th>\n",
       "      <th>job_Writer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.407826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.224130</td>\n",
       "      <td>-0.829155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.230039</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.406650</td>\n",
       "      <td>-0.254220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.934149</td>\n",
       "      <td>0</td>\n",
       "      <td>0.675752</td>\n",
       "      <td>0.665676</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.158132</td>\n",
       "      <td>0</td>\n",
       "      <td>0.423813</td>\n",
       "      <td>0.378209</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.177094</td>\n",
       "      <td>0</td>\n",
       "      <td>0.206271</td>\n",
       "      <td>-0.714168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296670</th>\n",
       "      <td>-0.341769</td>\n",
       "      <td>0</td>\n",
       "      <td>1.706798</td>\n",
       "      <td>0.665676</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296671</th>\n",
       "      <td>-0.116339</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010618</td>\n",
       "      <td>-0.369207</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296672</th>\n",
       "      <td>0.221930</td>\n",
       "      <td>0</td>\n",
       "      <td>0.637482</td>\n",
       "      <td>0.378209</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296673</th>\n",
       "      <td>0.028375</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333134</td>\n",
       "      <td>-0.369207</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296674</th>\n",
       "      <td>-0.412005</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.114146</td>\n",
       "      <td>-1.231609</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1296675 rows Ã— 1454 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              amt  is_fraud  distance       age  category_food_dining  \\\n",
       "0       -0.407826         0  0.224130 -0.829155                     0   \n",
       "1        0.230039         0 -1.406650 -0.254220                     0   \n",
       "2        0.934149         0  0.675752  0.665676                     0   \n",
       "3       -0.158132         0  0.423813  0.378209                     0   \n",
       "4       -0.177094         0  0.206271 -0.714168                     0   \n",
       "...           ...       ...       ...       ...                   ...   \n",
       "1296670 -0.341769         0  1.706798  0.665676                     0   \n",
       "1296671 -0.116339         0  0.010618 -0.369207                     1   \n",
       "1296672  0.221930         0  0.637482  0.378209                     1   \n",
       "1296673  0.028375         0  0.333134 -0.369207                     1   \n",
       "1296674 -0.412005         0 -0.114146 -1.231609                     1   \n",
       "\n",
       "         category_gas_transport  category_grocery_net  category_grocery_pos  \\\n",
       "0                             0                     0                     0   \n",
       "1                             0                     0                     1   \n",
       "2                             0                     0                     0   \n",
       "3                             1                     0                     0   \n",
       "4                             0                     0                     0   \n",
       "...                         ...                   ...                   ...   \n",
       "1296670                       0                     0                     0   \n",
       "1296671                       0                     0                     0   \n",
       "1296672                       0                     0                     0   \n",
       "1296673                       0                     0                     0   \n",
       "1296674                       0                     0                     0   \n",
       "\n",
       "         category_health_fitness  category_home  ...  job_Visual merchandiser  \\\n",
       "0                              0              0  ...                        0   \n",
       "1                              0              0  ...                        0   \n",
       "2                              0              0  ...                        0   \n",
       "3                              0              0  ...                        0   \n",
       "4                              0              0  ...                        0   \n",
       "...                          ...            ...  ...                      ...   \n",
       "1296670                        0              0  ...                        0   \n",
       "1296671                        0              0  ...                        0   \n",
       "1296672                        0              0  ...                        0   \n",
       "1296673                        0              0  ...                        0   \n",
       "1296674                        0              0  ...                        0   \n",
       "\n",
       "         job_Volunteer coordinator  job_Warden/ranger  job_Warehouse manager  \\\n",
       "0                                0                  0                      0   \n",
       "1                                0                  0                      0   \n",
       "2                                0                  0                      0   \n",
       "3                                0                  0                      0   \n",
       "4                                0                  0                      0   \n",
       "...                            ...                ...                    ...   \n",
       "1296670                          0                  0                      0   \n",
       "1296671                          0                  0                      0   \n",
       "1296672                          0                  0                      0   \n",
       "1296673                          1                  0                      0   \n",
       "1296674                          0                  0                      0   \n",
       "\n",
       "         job_Waste management officer  job_Water engineer  \\\n",
       "0                                   0                   0   \n",
       "1                                   0                   0   \n",
       "2                                   0                   0   \n",
       "3                                   0                   0   \n",
       "4                                   0                   0   \n",
       "...                               ...                 ...   \n",
       "1296670                             0                   0   \n",
       "1296671                             0                   0   \n",
       "1296672                             0                   0   \n",
       "1296673                             0                   0   \n",
       "1296674                             0                   0   \n",
       "\n",
       "         job_Water quality scientist  job_Web designer  \\\n",
       "0                                  0                 0   \n",
       "1                                  0                 0   \n",
       "2                                  0                 0   \n",
       "3                                  0                 0   \n",
       "4                                  0                 0   \n",
       "...                              ...               ...   \n",
       "1296670                            0                 0   \n",
       "1296671                            0                 0   \n",
       "1296672                            0                 0   \n",
       "1296673                            0                 0   \n",
       "1296674                            0                 0   \n",
       "\n",
       "         job_Wellsite geologist  job_Writer  \n",
       "0                             0           0  \n",
       "1                             0           0  \n",
       "2                             0           0  \n",
       "3                             0           0  \n",
       "4                             0           0  \n",
       "...                         ...         ...  \n",
       "1296670                       0           0  \n",
       "1296671                       0           0  \n",
       "1296672                       0           0  \n",
       "1296673                       0           0  \n",
       "1296674                       0           0  \n",
       "\n",
       "[1296675 rows x 1454 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "546d4bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only those columns in test_df that are in train_df\n",
    "test_df = test_df[train_df.columns.intersection(test_df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d0c534f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[list(set(train_df.columns)-set(test_df.columns))]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a414a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = test_df.drop('is_fraud', axis=1)\n",
    "y_test = test_df['is_fraud']   \n",
    "X_test_copy=X_test.copy()\n",
    "X_test = X_test.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d2e8fdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amt</th>\n",
       "      <th>distance</th>\n",
       "      <th>age</th>\n",
       "      <th>category_food_dining</th>\n",
       "      <th>category_gas_transport</th>\n",
       "      <th>category_grocery_net</th>\n",
       "      <th>category_grocery_pos</th>\n",
       "      <th>category_health_fitness</th>\n",
       "      <th>category_home</th>\n",
       "      <th>category_kids_pets</th>\n",
       "      <th>...</th>\n",
       "      <th>job_Veterinary surgeon</th>\n",
       "      <th>city_Pleasant Hill</th>\n",
       "      <th>city_Queen Anne</th>\n",
       "      <th>job_Engineer, site</th>\n",
       "      <th>city_Madisonville</th>\n",
       "      <th>city_West Frankfort</th>\n",
       "      <th>city_Mineral</th>\n",
       "      <th>city_Isanti</th>\n",
       "      <th>city_Wappapello</th>\n",
       "      <th>city_Ashland</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.420988</td>\n",
       "      <td>-1.414700</td>\n",
       "      <td>0.320715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.252695</td>\n",
       "      <td>0.749606</td>\n",
       "      <td>-0.944142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.181336</td>\n",
       "      <td>-0.476351</td>\n",
       "      <td>0.148235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.064255</td>\n",
       "      <td>-1.433114</td>\n",
       "      <td>-0.771661</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.418929</td>\n",
       "      <td>1.385934</td>\n",
       "      <td>1.068131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555714</th>\n",
       "      <td>-0.165804</td>\n",
       "      <td>-0.136825</td>\n",
       "      <td>0.435702</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555715</th>\n",
       "      <td>0.258795</td>\n",
       "      <td>0.655854</td>\n",
       "      <td>-1.519077</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555716</th>\n",
       "      <td>0.103102</td>\n",
       "      <td>0.491906</td>\n",
       "      <td>-0.484194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555717</th>\n",
       "      <td>-0.388988</td>\n",
       "      <td>-0.579572</td>\n",
       "      <td>0.435702</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555718</th>\n",
       "      <td>-0.200985</td>\n",
       "      <td>-0.415456</td>\n",
       "      <td>-1.116622</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>555719 rows Ã— 1453 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             amt  distance       age  category_food_dining  \\\n",
       "0      -0.420988 -1.414700  0.320715                     0   \n",
       "1      -0.252695  0.749606 -0.944142                     0   \n",
       "2      -0.181336 -0.476351  0.148235                     0   \n",
       "3      -0.064255 -1.433114 -0.771661                     0   \n",
       "4      -0.418929  1.385934  1.068131                     0   \n",
       "...          ...       ...       ...                   ...   \n",
       "555714 -0.165804 -0.136825  0.435702                     0   \n",
       "555715  0.258795  0.655854 -1.519077                     0   \n",
       "555716  0.103102  0.491906 -0.484194                     0   \n",
       "555717 -0.388988 -0.579572  0.435702                     0   \n",
       "555718 -0.200985 -0.415456 -1.116622                     0   \n",
       "\n",
       "        category_gas_transport  category_grocery_net  category_grocery_pos  \\\n",
       "0                            0                     0                     0   \n",
       "1                            0                     0                     0   \n",
       "2                            0                     0                     0   \n",
       "3                            0                     0                     0   \n",
       "4                            0                     0                     0   \n",
       "...                        ...                   ...                   ...   \n",
       "555714                       0                     0                     0   \n",
       "555715                       0                     0                     0   \n",
       "555716                       0                     0                     0   \n",
       "555717                       0                     0                     0   \n",
       "555718                       0                     0                     0   \n",
       "\n",
       "        category_health_fitness  category_home  category_kids_pets  ...  \\\n",
       "0                             0              0                   0  ...   \n",
       "1                             0              0                   0  ...   \n",
       "2                             1              0                   0  ...   \n",
       "3                             0              0                   0  ...   \n",
       "4                             0              0                   0  ...   \n",
       "...                         ...            ...                 ...  ...   \n",
       "555714                        1              0                   0  ...   \n",
       "555715                        0              0                   1  ...   \n",
       "555716                        0              0                   1  ...   \n",
       "555717                        0              0                   0  ...   \n",
       "555718                        0              0                   0  ...   \n",
       "\n",
       "        job_Veterinary surgeon  city_Pleasant Hill  city_Queen Anne  \\\n",
       "0                            0                   0                0   \n",
       "1                            0                   0                0   \n",
       "2                            0                   0                0   \n",
       "3                            0                   0                0   \n",
       "4                            0                   0                0   \n",
       "...                        ...                 ...              ...   \n",
       "555714                       0                   0                0   \n",
       "555715                       0                   0                0   \n",
       "555716                       0                   0                0   \n",
       "555717                       0                   0                0   \n",
       "555718                       0                   0                0   \n",
       "\n",
       "        job_Engineer, site  city_Madisonville  city_West Frankfort  \\\n",
       "0                        0                  0                    0   \n",
       "1                        0                  0                    0   \n",
       "2                        0                  0                    0   \n",
       "3                        0                  0                    0   \n",
       "4                        0                  0                    0   \n",
       "...                    ...                ...                  ...   \n",
       "555714                   0                  0                    0   \n",
       "555715                   0                  0                    0   \n",
       "555716                   0                  0                    0   \n",
       "555717                   0                  0                    0   \n",
       "555718                   0                  0                    0   \n",
       "\n",
       "        city_Mineral  city_Isanti  city_Wappapello  city_Ashland  \n",
       "0                  0            0                0             0  \n",
       "1                  0            0                0             0  \n",
       "2                  0            0                0             0  \n",
       "3                  0            0                0             0  \n",
       "4                  0            0                0             0  \n",
       "...              ...          ...              ...           ...  \n",
       "555714             0            0                0             0  \n",
       "555715             0            0                0             0  \n",
       "555716             0            0                0             0  \n",
       "555717             0            0                0             0  \n",
       "555718             0            0                0             0  \n",
       "\n",
       "[555719 rows x 1453 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1f138720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_copy.compare(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6707d405",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64'), dtype('int32'), dtype('int64')], dtype=object)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"column types\":X_test.dtypes})[\"column types\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dff0af3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d638395e",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "# Convert to tensors\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4a9e72fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.03      0.06    553574\n",
      "         1.0       0.00      1.00      0.01      2145\n",
      "\n",
      "    accuracy                           0.03    555719\n",
      "   macro avg       0.50      0.51      0.03    555719\n",
      "weighted avg       1.00      0.03      0.05    555719\n",
      "\n",
      "[[ 15675 537899]\n",
      " [     8   2137]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "y_test_pred = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, _ in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        y_test_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "y_test_pred = np.array(y_test_pred)\n",
    "y_test_pred = (y_test_pred > 0.5).astype(int)\n",
    "\n",
    "y_test_true = y_test_tensor.cpu().numpy()\n",
    "print(classification_report(y_test_true, y_test_pred))\n",
    "print(confusion_matrix(y_test_true, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b24eb75",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.90      0.94    553574\n",
    "         1.0       0.00      0.07      0.00      2145\n",
    "\n",
    "    accuracy                           0.90    555719\n",
    "   macro avg       0.50      0.48      0.47    555719\n",
    "weighted avg       0.99      0.90      0.94    555719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "53c4e2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    257815\n",
      "           1       0.02      0.03      0.02      1520\n",
      "\n",
      "    accuracy                           0.98    259335\n",
      "   macro avg       0.51      0.51      0.51    259335\n",
      "weighted avg       0.99      0.98      0.99    259335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "iso_forest.fit(X_train)\n",
    "y_val_pred = iso_forest.predict(X_val)\n",
    "y_val_pred = [1 if x == -1 else 0 for x in y_val_pred]\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9af234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
