{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zcWElZZA7rzX"
   },
   "source": [
    "\n",
    "# Table Question Answering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZqviV15sO31"
   },
   "source": [
    "Table Question Answering (Table QA) refers to providing precise answers from tables to answer a user's question. With recent works on Table QA, is it now possible to answer natural language queries from tabular data. This notebook demonstrates how you can build a Table QA system that can answer your natural language queries using the Pinecone vector database. \n",
    "\n",
    "We need three main components to build the Table QA system:\n",
    "\n",
    "- A vector index to store table embeddings\n",
    "- A retriever model for embedding queries and tables\n",
    "- A reader model to read the tables and extract answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-h-MW6FJxTtT"
   },
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:19:41.915874Z",
     "iopub.status.busy": "2024-12-31T16:19:41.915593Z",
     "iopub.status.idle": "2024-12-31T16:34:01.485529Z",
     "shell.execute_reply": "2024-12-31T16:34:01.484528Z",
     "shell.execute_reply.started": "2024-12-31T16:19:41.915854Z"
    },
    "id": "OXXxZ_9q75RH",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Collecting pinecone-client\n",
      "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: sentence_transformers in c:\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Collecting torch-scatter\n",
      "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\anaconda3\\lib\\site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\anaconda3\\lib\\site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\anaconda3\\lib\\site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\anaconda3\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\anaconda3\\lib\\site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in c:\\anaconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in c:\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in c:\\anaconda3\\lib\\site-packages (from fsspec[http]>=2021.11.1->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\anaconda3\\lib\\site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in c:\\anaconda3\\lib\\site-packages (from datasets) (0.23.4)\n",
      "Requirement already satisfied: packaging in c:\\anaconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: responses<0.19 in c:\\anaconda3\\lib\\site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\anaconda3\\lib\\site-packages (from pinecone-client) (2024.8.30)\n",
      "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n",
      "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\anaconda3\\lib\\site-packages (from pinecone-client) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\anaconda3\\lib\\site-packages (from pinecone-client) (1.26.16)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence_transformers)\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\anaconda3\\lib\\site-packages (from sentence_transformers) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: Pillow in c:\\anaconda3\\lib\\site-packages (from sentence_transformers) (10.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: filelock in c:\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: six in c:\\anaconda3\\lib\\site-packages (from responses<0.19->datasets) (1.16.0)\n",
      "Requirement already satisfied: sympy in c:\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Collecting huggingface-hub<1.0.0,>=0.11.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2022.7.9)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.34.0->sentence_transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Downloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
      "Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
      "Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 2.6/10.1 MB 12.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.3/10.1 MB 15.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.1 MB 15.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.1/10.1 MB 14.0 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 15.2 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: torch-scatter\n",
      "  Building wheel for torch-scatter (setup.py): started\n",
      "  Building wheel for torch-scatter (setup.py): still running...\n",
      "  Building wheel for torch-scatter (setup.py): still running...\n",
      "  Building wheel for torch-scatter (setup.py): still running...\n",
      "  Building wheel for torch-scatter (setup.py): still running...\n",
      "  Building wheel for torch-scatter (setup.py): finished with status 'done'\n",
      "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp311-cp311-win_amd64.whl size=332904 sha256=eed2e2cbcc273c92fb6ab32a151abfd86fc2594eeb29ab7512eb05d48c578795\n",
      "  Stored in directory: c:\\users\\u013709\\appdata\\local\\pip\\cache\\wheels\\b8\\d4\\0e\\a80af2465354ea7355a2c153b11af2da739cfcf08b6c0b28e2\n",
      "Successfully built torch-scatter\n",
      "Installing collected packages: torch-scatter, pinecone-plugin-interface, pinecone-plugin-inference, huggingface-hub, tokenizers, pinecone-client, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.23.4\n",
      "    Uninstalling huggingface-hub-0.23.4:\n",
      "      Successfully uninstalled huggingface-hub-0.23.4\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.31.0\n",
      "    Uninstalling transformers-4.31.0:\n",
      "      Successfully uninstalled transformers-4.31.0\n",
      "Successfully installed huggingface-hub-0.27.0 pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0 pinecone-plugin-interface-0.0.7 tokenizers-0.21.0 torch-scatter-2.1.2 transformers-4.47.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~lotly (C:\\Anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~y-cpuinfo (C:\\Anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~lotly (C:\\Anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~y-cpuinfo (C:\\Anaconda3\\Lib\\site-packages)\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Anaconda3\\Lib\\site-packages\\~okenizers'.\n",
      "  You can safely remove it manually.\n",
      "WARNING: Ignoring invalid distribution ~lotly (C:\\Anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~y-cpuinfo (C:\\Anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# torch-scatter may take few minutes to install\n",
    "!pip install datasets pinecone-client sentence_transformers torch-scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyqzTw5RBeEa"
   },
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ouitEo-0XQC"
   },
   "source": [
    "We will work with a subset of the Open Table-and-Text Question Answering ([OTT-QA](https://github.com/wenhuchen/OTT-QA)) dataset, consisting of texts and tables from Wikipedia. The subset contains 20,000 tables, and it can be loaded from the Huggigface Datasets hub as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:34:01.487146Z",
     "iopub.status.busy": "2024-12-31T16:34:01.486836Z",
     "iopub.status.idle": "2024-12-31T16:34:05.103923Z",
     "shell.execute_reply": "2024-12-31T16:34:05.102955Z",
     "shell.execute_reply.started": "2024-12-31T16:34:01.487113Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in c:\\anaconda3\\lib\\site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\anaconda3\\lib\\site-packages (from datasets) (1.24.3)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-18.1.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\anaconda3\\lib\\site-packages (from datasets) (2.0.3)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: xxhash in c:\\anaconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\anaconda3\\lib\\site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\anaconda3\\lib\\site-packages (from datasets) (0.27.0)\n",
      "Requirement already satisfied: packaging in c:\\anaconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Downloading pyarrow-18.1.0-cp311-cp311-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 3.1/25.1 MB 15.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 4.7/25.1 MB 14.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.6/25.1 MB 10.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 11.3/25.1 MB 12.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 14.7/25.1 MB 13.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 17.3/25.1 MB 13.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 20.7/25.1 MB 13.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.3/25.1 MB 13.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.9/25.1 MB 13.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 11.8 MB/s eta 0:00:00\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, requests, pyarrow, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 11.0.0\n",
      "    Uninstalling pyarrow-11.0.0:\n",
      "      Successfully uninstalled pyarrow-11.0.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.12.0\n",
      "    Uninstalling datasets-2.12.0:\n",
      "      Successfully uninstalled datasets-2.12.0\n",
      "Successfully installed datasets-3.2.0 pyarrow-18.1.0 requests-2.32.3 tqdm-4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~lotly (C:\\Anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~y-cpuinfo (C:\\Anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~lotly (C:\\Anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~y-cpuinfo (C:\\Anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~lotly (C:\\Anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~y-cpuinfo (C:\\Anaconda3\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.75 requires requests_mock, which is not installed.\n",
      "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires PyYAML==6.0.1, but you have pyyaml 6.0 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
      "flask-monitoringdashboard 3.3.2 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
      "langchain-community 0.2.6 requires langchain<0.3.0,>=0.2.6, but you have langchain 0.0.225 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:34:05.105841Z",
     "iopub.status.busy": "2024-12-31T16:34:05.105554Z",
     "iopub.status.idle": "2024-12-31T16:34:09.230721Z",
     "shell.execute_reply": "2024-12-31T16:34:09.230039Z",
     "shell.execute_reply.started": "2024-12-31T16:34:05.105818Z"
    },
    "id": "kKf3UJJFlM2R",
    "outputId": "ea39017c-86ea-454d-b155-8c203acecf83",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee69f74087dd4e51b2dee0d6a5c0c3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/700 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f10e547f30b43fca7bb7258f5a9ed21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-07e37a7da4916928.parquet:   0%|          | 0.00/23.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1fd6ebe2d64368bde62892f09e5821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['url', 'title', 'header', 'data', 'section_title', 'section_text', 'uid', 'intro'],\n",
       "    num_rows: 20000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the dataset from huggingface datasets hub\n",
    "data = load_dataset(\"ashraq/ott-qa-20k\", split=\"train\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:34:09.232304Z",
     "iopub.status.busy": "2024-12-31T16:34:09.231908Z",
     "iopub.status.idle": "2024-12-31T16:34:09.238343Z",
     "shell.execute_reply": "2024-12-31T16:34:09.237506Z",
     "shell.execute_reply.started": "2024-12-31T16:34:09.232281Z"
    },
    "id": "Dv_CU6hs1Yd6",
    "outputId": "5b0d52a3-f138-4328-dafc-a54d186e4ef7",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://en.wikipedia.org/wiki/1976_New_York_Mets_season',\n",
       " 'title': '1976 New York Mets season',\n",
       " 'header': ['Level', 'Team', 'League', 'Manager'],\n",
       " 'data': [['AAA', 'Tidewater Tides', 'International League', 'Tom Burgess'],\n",
       "  ['AA', 'Jackson Mets', 'Texas League', 'John Antonelli'],\n",
       "  ['A', 'Lynchburg Mets', 'Carolina League', 'Jack Aker'],\n",
       "  ['A', 'Wausau Mets', 'Midwest League', 'Bill Monbouquette'],\n",
       "  ['Rookie', 'Marion Mets', 'Appalachian League', 'Al Jackson']],\n",
       " 'section_title': 'Farm system',\n",
       " 'section_text': 'See also : Minor League Baseball',\n",
       " 'uid': '1976_New_York_Mets_season_7',\n",
       " 'intro': 'The New York Mets season was the 15th regular season for the Mets, who played home games at Shea Stadium. Led by manager Joe Frazier, the team had an 86-76 record and finished in third place in the National League East.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wz0Z6qF_EUzM"
   },
   "source": [
    "As we can see, the dataset includes both textual and tabular data that are related to one another. Let's extract and transform the dataset's tables into pandas dataframes as we will only be using the tables in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:34:09.239480Z",
     "iopub.status.busy": "2024-12-31T16:34:09.239178Z",
     "iopub.status.idle": "2024-12-31T16:34:18.934673Z",
     "shell.execute_reply": "2024-12-31T16:34:18.933904Z",
     "shell.execute_reply.started": "2024-12-31T16:34:09.239448Z"
    },
    "id": "BmoFdpptEXHO",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# store all tables in the tables list\n",
    "tables = []\n",
    "# loop through the dataset and convert tabular data to pandas dataframes\n",
    "for doc in data:\n",
    "    table = pd.DataFrame(doc[\"data\"], columns=doc[\"header\"])\n",
    "    tables.append(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:34:18.935871Z",
     "iopub.status.busy": "2024-12-31T16:34:18.935549Z",
     "iopub.status.idle": "2024-12-31T16:34:18.952272Z",
     "shell.execute_reply": "2024-12-31T16:34:18.951434Z",
     "shell.execute_reply.started": "2024-12-31T16:34:18.935835Z"
    },
    "id": "c56PfwR4F1cZ",
    "outputId": "5cebb3d9-754d-4dc2-b1b5-3536552b3907",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Team</th>\n",
       "      <th>League</th>\n",
       "      <th>Manager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAA</td>\n",
       "      <td>Tidewater Tides</td>\n",
       "      <td>International League</td>\n",
       "      <td>Tom Burgess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>Jackson Mets</td>\n",
       "      <td>Texas League</td>\n",
       "      <td>John Antonelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>Lynchburg Mets</td>\n",
       "      <td>Carolina League</td>\n",
       "      <td>Jack Aker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>Wausau Mets</td>\n",
       "      <td>Midwest League</td>\n",
       "      <td>Bill Monbouquette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rookie</td>\n",
       "      <td>Marion Mets</td>\n",
       "      <td>Appalachian League</td>\n",
       "      <td>Al Jackson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Level             Team                League            Manager\n",
       "0     AAA  Tidewater Tides  International League        Tom Burgess\n",
       "1      AA     Jackson Mets          Texas League     John Antonelli\n",
       "2       A   Lynchburg Mets       Carolina League          Jack Aker\n",
       "3       A      Wausau Mets        Midwest League  Bill Monbouquette\n",
       "4  Rookie      Marion Mets    Appalachian League         Al Jackson"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0n61NMn9-HZv"
   },
   "source": [
    "# Initialize Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNfBXFk4Arh4"
   },
   "source": [
    "The retriever transforms natural language queries and tabular data into embeddings/vectors. It will generate embeddings in a way that the natural language questions and tables containing answers to our questions are nearby in the vector space.\n",
    "\n",
    "We will use a SentenceTransformer model trained specifically for embedding tabular data for retrieval tasks. The model can be loaded from the Huggingface Models hub as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:34:18.953525Z",
     "iopub.status.busy": "2024-12-31T16:34:18.953227Z",
     "iopub.status.idle": "2024-12-31T16:34:22.378820Z",
     "shell.execute_reply": "2024-12-31T16:34:22.377689Z",
     "shell.execute_reply.started": "2024-12-31T16:34:18.953494Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:34:22.381914Z",
     "iopub.status.busy": "2024-12-31T16:34:22.381668Z",
     "iopub.status.idle": "2024-12-31T16:34:39.733065Z",
     "shell.execute_reply": "2024-12-31T16:34:39.732107Z",
     "shell.execute_reply.started": "2024-12-31T16:34:22.381894Z"
    },
    "id": "cfonlEiX-KQA",
    "outputId": "ffa1c02b-79d7-4360-938c-a58955384d29",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060175e949cd42b99174f0fe384f0149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4a3244cf9d4f9fac7e8adc4212cfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e8961c235542d59a831c2b971c6616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887cb91d3ff944268140dae00460a01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f08396748c4ea2aa1db44218a6c9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1310200228b45889515ad00a0c5abd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/576 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b198e8099e4d48db8c35ca8a293f9e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b907eca61946bbb6d7060f0a8833cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/345 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2280a4009133441cbe6341b1d69bdaaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c78ffaef0c486b98e425165a99019c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38f6d3a272542688f0df18206038939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b457232fe3b4d1f9cd784f6205263b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# set device to GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# load the table embedding model from huggingface models hub\n",
    "retriever = SentenceTransformer(\"deepset/all-mpnet-base-v2-table\", device=device)\n",
    "retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gypflS135_Y4"
   },
   "source": [
    "The retriever expects tables to be in a particular format. Let's write a function to convert the tables to this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:34:39.735468Z",
     "iopub.status.busy": "2024-12-31T16:34:39.734860Z",
     "iopub.status.idle": "2024-12-31T16:34:39.739623Z",
     "shell.execute_reply": "2024-12-31T16:34:39.738901Z",
     "shell.execute_reply.started": "2024-12-31T16:34:39.735442Z"
    },
    "id": "9-MqljKaAarE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def _preprocess_tables(tables: list):\n",
    "    processed = []\n",
    "    # loop through all tables\n",
    "    for table in tables:\n",
    "        # convert the table to csv and \n",
    "        processed_table = \"\\n\".join([table.to_csv(index=False)])\n",
    "        # add the processed table to processed list\n",
    "        processed.append(processed_table)\n",
    "    return processed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4T_eMtEHlw9"
   },
   "source": [
    "Notice that we are only using tables here. However, if you want the retriever to take the metadata into account while retrieving the tables, you can join any metadata strings, such as title, section_title, etc., separated by new line characters at the beginning of the processed table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIdluqrZIH0X"
   },
   "source": [
    "Let's take a look at the formatted tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:34:39.740717Z",
     "iopub.status.busy": "2024-12-31T16:34:39.740441Z",
     "iopub.status.idle": "2024-12-31T16:34:46.043652Z",
     "shell.execute_reply": "2024-12-31T16:34:46.042817Z",
     "shell.execute_reply.started": "2024-12-31T16:34:39.740683Z"
    },
    "id": "4NTu2-qqAbk2",
    "outputId": "e4bee59c-f90c-4e38-ce24-06a769f8b402",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Level,Team,League,Manager\\nAAA,Tidewater Tides,International League,Tom Burgess\\nAA,Jackson Mets,Texas League,John Antonelli\\nA,Lynchburg Mets,Carolina League,Jack Aker\\nA,Wausau Mets,Midwest League,Bill Monbouquette\\nRookie,Marion Mets,Appalachian League,Al Jackson\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format all the dataframes in the tables list\n",
    "processed_tables = _preprocess_tables(tables)\n",
    "# display the formatted table\n",
    "processed_tables[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "processed_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FI8TLf5CJFeq"
   },
   "source": [
    "The formatted table may not make sense to us, but the embedding model is trained to understand it and generate accurate embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpUcVljhCIaO"
   },
   "source": [
    "# Initialize Pinecone Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8RzP4snKuCW"
   },
   "source": [
    "We will use the Pinecone vector database as our vector index. The Pinecone index stores vector representations of our tables which we can retrieve using a natural language query (query vector). Pinecone does this by computing the similarity between the query vector and the embedded tables stored in the vector index. \n",
    "\n",
    "To use Pinecone, we first need to initialize a connection to Pinecone. For this, we need a [free API key](https://app.pinecone.io/), and then we initialize the connection like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:34:46.092090Z",
     "iopub.status.busy": "2024-12-31T16:34:46.091838Z",
     "iopub.status.idle": "2024-12-31T16:34:51.171547Z",
     "shell.execute_reply": "2024-12-31T16:34:51.170399Z",
     "shell.execute_reply.started": "2024-12-31T16:34:46.092069Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
      "Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.9.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:34:51.172824Z",
     "iopub.status.busy": "2024-12-31T16:34:51.172583Z",
     "iopub.status.idle": "2024-12-31T16:34:52.493548Z",
     "shell.execute_reply": "2024-12-31T16:34:52.492816Z",
     "shell.execute_reply.started": "2024-12-31T16:34:51.172803Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class Retriever:\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer('deepset/all-mpnet-base-v2-table')\n",
    "\n",
    "    def encode(self, texts):\n",
    "        return self.model.encode(texts)\n",
    "\n",
    "retriever = Retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:34:52.494872Z",
     "iopub.status.busy": "2024-12-31T16:34:52.494536Z",
     "iopub.status.idle": "2024-12-31T16:44:05.395783Z",
     "shell.execute_reply": "2024-12-31T16:44:05.394849Z",
     "shell.execute_reply.started": "2024-12-31T16:34:52.494841Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Define the index name\n",
    "index_name = \"table-qa\"\n",
    "\n",
    "# Check if the index exists (FAISS does not have a direct method to list indexes, so we manage it manually)\n",
    "index_exists = False\n",
    "try:\n",
    "    faiss.read_index(f\"{index_name}.index\")\n",
    "    index_exists = True\n",
    "except:\n",
    "    index_exists = False\n",
    "\n",
    "# Create the index if it does not exist\n",
    "if not index_exists:\n",
    "    dimension = 768  # Change dimension to 384\n",
    "    index = faiss.IndexFlatL2(dimension)  # Using L2 distance (Euclidean distance)\n",
    "    faiss.write_index(index, f\"{index_name}.index\")\n",
    "else:\n",
    "    # Load the existing index\n",
    "    index = faiss.read_index(f\"{index_name}.index\")\n",
    "\n",
    "# Function to add vectors to the index and save it\n",
    "def add_vectors_to_index(vectors):\n",
    "    global index\n",
    "    assert vectors.shape[1] == index.d, f\"Vector dimension {vectors.shape[1]} does not match index dimension {index.d}\"\n",
    "    index.add(vectors)\n",
    "    faiss.write_index(index, f\"{index_name}.index\")\n",
    "\n",
    "# Initialize the retriever with Sentence Transformers\n",
    "class Retriever:\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer('deepset/all-mpnet-base-v2-table')\n",
    "\n",
    "    def encode(self, texts):\n",
    "        return self.model.encode(texts)\n",
    "\n",
    "retriever = Retriever()\n",
    "# We will use batches of 64\n",
    "batch_size = 64\n",
    "\n",
    "for i in tqdm(range(0, len(processed_tables), batch_size)):\n",
    "    # Find end of batch\n",
    "    i_end = min(i + batch_size, len(processed_tables))\n",
    "    # Extract batch\n",
    "    batch = processed_tables[i:i_end]\n",
    "    # Generate embeddings for batch\n",
    "    emb = retriever.encode(batch).astype('float32')\n",
    "    # Check the dimensions of the embeddings\n",
    "    assert emb.shape[1] == 768, f\"Embedding dimension {emb.shape[1]} does not match expected dimension 384\"\n",
    "    # Add vectors to the FAISS index\n",
    "    add_vectors_to_index(emb)\n",
    "\n",
    "# FAISS does not have a direct method to describe index stats, but we can print the total number of vectors added\n",
    "print(f\"Total number of vectors in the index: {index.ntotal}\")\n",
    "\n",
    "# Example query\n",
    "query = \"which country has the highest GDP in 2020?\"\n",
    "\n",
    "# Generate embedding for the query\n",
    "xq = retriever.encode([query]).astype('float32')\n",
    "\n",
    "# Check the shape of the query embedding\n",
    "print(\"Query embedding shape:\", xq.shape)\n",
    "\n",
    "# Query FAISS index to find the table containing the answer to the query\n",
    "k = 1  # Number of nearest neighbors\n",
    "distances, indices = index.search(xq, k)\n",
    "\n",
    "# Print the result\n",
    "print(\"Indices of nearest neighbors:\", indices)\n",
    "print(\"Distances to nearest neighbors:\", distances)\n",
    "\n",
    "# Verify the data in the index\n",
    "print(\"Total number of vectors in the index:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:44:05.397036Z",
     "iopub.status.busy": "2024-12-31T16:44:05.396748Z",
     "iopub.status.idle": "2024-12-31T16:44:05.449526Z",
     "shell.execute_reply": "2024-12-31T16:44:05.448636Z",
     "shell.execute_reply.started": "2024-12-31T16:44:05.397005Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41fa88d1fbc143a895ff0df3172ed252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query embedding shape: (1, 768)\n",
      "Indices of nearest neighbors: [[19931]]\n",
      "Distances to nearest neighbors: [[0.35582632]]\n",
      "Total number of vectors in the index: 20000\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"which country has the highest GDP in 2020?\"\n",
    "\n",
    "# Generate embedding for the query\n",
    "xq = retriever.encode([query]).astype('float32')\n",
    "\n",
    "# Check the shape of the query embedding\n",
    "print(\"Query embedding shape:\", xq.shape)\n",
    "\n",
    "# Query FAISS index to find the table containing the answer to the query\n",
    "k = 1  # Number of nearest neighbors\n",
    "distances, indices = index.search(xq, k)\n",
    "\n",
    "# Print the result\n",
    "print(\"Indices of nearest neighbors:\", indices)\n",
    "print(\"Distances to nearest neighbors:\", distances)\n",
    "\n",
    "# Verify the data in the index\n",
    "print(\"Total number of vectors in the index:\", index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results = [processed_tables[i] for i in indices[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:44:05.450643Z",
     "iopub.status.busy": "2024-12-31T16:44:05.450362Z",
     "iopub.status.idle": "2024-12-31T16:44:05.454545Z",
     "shell.execute_reply": "2024-12-31T16:44:05.453666Z",
     "shell.execute_reply.started": "2024-12-31T16:44:05.450622Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results = [tables[i] for i in indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:44:05.471031Z",
     "iopub.status.busy": "2024-12-31T16:44:05.470698Z",
     "iopub.status.idle": "2024-12-31T16:44:05.487284Z",
     "shell.execute_reply": "2024-12-31T16:44:05.486426Z",
     "shell.execute_reply.started": "2024-12-31T16:44:05.470982Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19931])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWqgjlaROvHX"
   },
   "source": [
    "Now we create a new index. We specify the metric type as \"cosine\" and dimension as 768 because the retriever we use to generate context embeddings outputs 768-dimension vectors. Pinecone will use cosine similarity to compute the similarity between the query and table embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LiHFszRrnRyC"
   },
   "source": [
    "Now the Pinecone index is ready for querying. Let's test to see if it returns tables relevant to our queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:44:05.488592Z",
     "iopub.status.busy": "2024-12-31T16:44:05.488197Z",
     "iopub.status.idle": "2024-12-31T16:44:05.508035Z",
     "shell.execute_reply": "2024-12-31T16:44:05.507114Z",
     "shell.execute_reply.started": "2024-12-31T16:44:05.488556Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rank,Country,\"GDP ( PPP , Peak Year ) millions...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Rank,Country,\"GDP ( PPP , Peak Year ) millions..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sx8zgRSYrVB8"
   },
   "source": [
    "The Pinecone index has returned the ```id``` of a table that would contain the answer to our query with 82.2% confidence. Let's see if this table actually contains the answer. We can use the returned ```id``` as an index to get the relevant pandas dataframe from the ```tables``` list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3A47xkzuPRx"
   },
   "source": [
    "The table returned by the Pinecone index indeed has the answer to our query. Now we need a model that can read this table and extract the precise answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssatLvB9BUe3"
   },
   "source": [
    "# Initialize Table Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dwePzfAvS0t"
   },
   "source": [
    "As the reader, we will use a TAPAS model fine-tuned for the Table QA task. TAPAS is a BERT-like Transformer model pretrained in a self-supervised manner on a large corpus of English language data from Wikipedia. We load the model and tokenizer from the Huggingface model hub into a question-answering pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:44:05.509419Z",
     "iopub.status.busy": "2024-12-31T16:44:05.509067Z",
     "iopub.status.idle": "2024-12-31T16:44:11.794992Z",
     "shell.execute_reply": "2024-12-31T16:44:11.794285Z",
     "shell.execute_reply.started": "2024-12-31T16:44:05.509385Z"
    },
    "id": "bG2umGVi71CD",
    "outputId": "2bde6f52-f322-4dca-d1de-80a33017c375",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d377f1c964e74a0b99e9bf01a67a169d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/490 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc968bf79b204f778c3f111436f3196c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/262k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c246bc3ccf44b609ea4f945c0395c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/154 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cced1b7351764ff19ce8fc5a6a338839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea045e5f106441086d1517ae6cc1db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline, TapasTokenizer, TapasForQuestionAnswering\n",
    "\n",
    "model_name = \"google/tapas-base-finetuned-wtq\"\n",
    "# load the tokenizer and the model from huggingface model hub\n",
    "tokenizer = TapasTokenizer.from_pretrained(model_name)\n",
    "model = TapasForQuestionAnswering.from_pretrained(model_name, local_files_only=False)\n",
    "# load the model and tokenizer into a question-answering pipeline\n",
    "pipe = pipeline(\"table-question-answering\",  model=model, tokenizer=tokenizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:58:14.904376Z",
     "iopub.status.busy": "2024-12-31T16:58:14.904056Z",
     "iopub.status.idle": "2024-12-31T16:58:14.915899Z",
     "shell.execute_reply": "2024-12-31T16:58:14.915073Z",
     "shell.execute_reply.started": "2024-12-31T16:58:14.904352Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>GDP ( PPP , Peak Year ) millions of USD</th>\n",
       "      <th>Peak Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>China</td>\n",
       "      <td>27,804,953</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>India</td>\n",
       "      <td>11,321,280</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Russia</td>\n",
       "      <td>4,389,960</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>3,778,134</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>3,596,841</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2,616,289</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>2,361,778</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>2,320,498</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>1,900,894</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Iran</td>\n",
       "      <td>1,637,215</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>1,427,432</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>1,377,535</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>1,339,812</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Poland</td>\n",
       "      <td>1,287,275</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>1,215,389</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>1,201,629</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>1,076,373</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>1,040,413</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>1,035,051</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>916,719</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank       Country GDP ( PPP , Peak Year ) millions of USD Peak Year\n",
       "0     1         China                              27,804,953      2020\n",
       "1     2         India                              11,321,280      2020\n",
       "2     3        Russia                               4,389,960      2019\n",
       "3     4     Indonesia                               3,778,134      2020\n",
       "4     5        Brazil                               3,596,841      2020\n",
       "5     6        Mexico                               2,616,289      2019\n",
       "6     7        Turkey                               2,361,778      2019\n",
       "7     8   South Korea                               2,320,498      2019\n",
       "8     9  Saudi Arabia                               1,900,894      2019\n",
       "9    10          Iran                               1,637,215      2017\n",
       "10   11         Egypt                               1,427,432      2020\n",
       "11   12      Thailand                               1,377,535      2019\n",
       "12   13        Taiwan                               1,339,812      2019\n",
       "13   14        Poland                               1,287,275      2019\n",
       "14   15       Nigeria                               1,215,389      2019\n",
       "15   16      Pakistan                               1,201,629      2019\n",
       "16   17      Malaysia                               1,076,373      2019\n",
       "17   18   Philippines                               1,040,413      2020\n",
       "18   19       Vietnam                               1,035,051      2020\n",
       "19   20     Argentina                                 916,719      2017"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[indices[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irYNVILy4iAq"
   },
   "source": [
    "Let's run the table returned by the Pinecone index and the query we used before into the question-answering pipeline to extract the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:58:24.010451Z",
     "iopub.status.busy": "2024-12-31T16:58:24.010152Z",
     "iopub.status.idle": "2024-12-31T16:58:24.467870Z",
     "shell.execute_reply": "2024-12-31T16:58:24.467005Z",
     "shell.execute_reply.started": "2024-12-31T16:58:24.010428Z"
    },
    "id": "teqRR63T1gTh",
    "outputId": "f5b25c5d-afce-4be3-99e5-2c16c6b892d9",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:2673: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:1472: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'China',\n",
       " 'coordinates': [(0, 1)],\n",
       " 'cells': ['China'],\n",
       " 'aggregator': 'NONE'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(table=tables[indices[0][0]], query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPx5qXw70U0c"
   },
   "source": [
    "The model has precisely answered our query. Let's run some more queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPSC0U6QRuSc"
   },
   "source": [
    "# Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFpoWLPP49Fo"
   },
   "source": [
    "First, we will define two function to handle our queries and extract answers from tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:58:51.230371Z",
     "iopub.status.busy": "2024-12-31T16:58:51.230065Z",
     "iopub.status.idle": "2024-12-31T16:58:51.234862Z",
     "shell.execute_reply": "2024-12-31T16:58:51.234065Z",
     "shell.execute_reply.started": "2024-12-31T16:58:51.230350Z"
    },
    "id": "Dn75qXt7U_hx",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def query_pinecone(query):\n",
    "    # generate embedding for the query\n",
    "    xq = retriever.encode([query]).astype('float32')\n",
    "\n",
    "    # Check the shape of the query embedding\n",
    "    print(\"Query embedding shape:\", xq.shape)\n",
    "    \n",
    "    # Query FAISS index to find the table containing the answer to the query\n",
    "    k = 1  # Number of nearest neighbors\n",
    "    distances, indices = index.search(xq, k)\n",
    "\n",
    "    # return the relevant table from the tables list\n",
    "    return tables[indices[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:58:54.372089Z",
     "iopub.status.busy": "2024-12-31T16:58:54.371738Z",
     "iopub.status.idle": "2024-12-31T16:58:54.376062Z",
     "shell.execute_reply": "2024-12-31T16:58:54.375086Z",
     "shell.execute_reply.started": "2024-12-31T16:58:54.372060Z"
    },
    "id": "jfdX3084WHxB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_answer_from_table(table, query):\n",
    "    # run the table and query through the question-answering pipeline\n",
    "    answers = pipe(table=table, query=query)\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:58:58.312922Z",
     "iopub.status.busy": "2024-12-31T16:58:58.312614Z",
     "iopub.status.idle": "2024-12-31T16:58:58.362041Z",
     "shell.execute_reply": "2024-12-31T16:58:58.361379Z",
     "shell.execute_reply.started": "2024-12-31T16:58:58.312898Z"
    },
    "id": "-l0-OkC69_N3",
    "outputId": "12aa9a04-61f0-4dcf-83e1-04a89d0d976d",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866c09b05ae7479fa7cf2f8da7935287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query embedding shape: (1, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Engine</th>\n",
       "      <th>Power Output</th>\n",
       "      <th>Max . Speed ( kph )</th>\n",
       "      <th>Dry Weight ( kg )</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fiat</td>\n",
       "      <td>805-405</td>\n",
       "      <td>FIAT 1979cc S6 supercharged</td>\n",
       "      <td>130 bhp</td>\n",
       "      <td>220</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>GPR ( P1 )</td>\n",
       "      <td>Alfa Romeo 1990cc S6</td>\n",
       "      <td>95 bhp</td>\n",
       "      <td>180</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Diatto</td>\n",
       "      <td>Tipo 20 S</td>\n",
       "      <td>Diatto 1997cc S4</td>\n",
       "      <td>75 bhp</td>\n",
       "      <td>155</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Type 32</td>\n",
       "      <td>Bugatti 1991cc S8</td>\n",
       "      <td>100 bhp</td>\n",
       "      <td>190</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Voisin</td>\n",
       "      <td>C6 Laboratoire</td>\n",
       "      <td>Voisin 1978cc S6</td>\n",
       "      <td>90 bhp</td>\n",
       "      <td>175</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sunbeam</td>\n",
       "      <td></td>\n",
       "      <td>Sunbeam 1988cc S6</td>\n",
       "      <td>108 bhp</td>\n",
       "      <td>180</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mercedes</td>\n",
       "      <td>M7294</td>\n",
       "      <td>Mercedes 1990cc S4 supercharged</td>\n",
       "      <td>120 bhp</td>\n",
       "      <td>180</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Benz</td>\n",
       "      <td>RH Tropfenwagen</td>\n",
       "      <td>Benz 1998cc S6</td>\n",
       "      <td>95 bhp</td>\n",
       "      <td>185</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Miller</td>\n",
       "      <td>122</td>\n",
       "      <td>Miller 1978cc S8</td>\n",
       "      <td>120 bhp</td>\n",
       "      <td>186</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Manufacturer            Model                           Engine Power Output  \\\n",
       "0         Fiat          805-405      FIAT 1979cc S6 supercharged      130 bhp   \n",
       "1   Alfa Romeo       GPR ( P1 )             Alfa Romeo 1990cc S6       95 bhp   \n",
       "2       Diatto        Tipo 20 S                 Diatto 1997cc S4       75 bhp   \n",
       "3      Bugatti          Type 32                Bugatti 1991cc S8      100 bhp   \n",
       "4       Voisin   C6 Laboratoire                 Voisin 1978cc S6       90 bhp   \n",
       "5      Sunbeam                                 Sunbeam 1988cc S6      108 bhp   \n",
       "6     Mercedes            M7294  Mercedes 1990cc S4 supercharged      120 bhp   \n",
       "7         Benz  RH Tropfenwagen                   Benz 1998cc S6       95 bhp   \n",
       "8       Miller              122                 Miller 1978cc S8      120 bhp   \n",
       "\n",
       "  Max . Speed ( kph ) Dry Weight ( kg )  \n",
       "0                 220               680  \n",
       "1                 180               850  \n",
       "2                 155               700  \n",
       "3                 190               660  \n",
       "4                 175               710  \n",
       "5                 180               675  \n",
       "6                 180               750  \n",
       "7                 185               745  \n",
       "8                 186               850  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"which car manufacturers produce cars with a top speed of above 180 kph?\"\n",
    "table = query_pinecone(query)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:59:02.543192Z",
     "iopub.status.busy": "2024-12-31T16:59:02.542851Z",
     "iopub.status.idle": "2024-12-31T16:59:02.615421Z",
     "shell.execute_reply": "2024-12-31T16:59:02.614540Z",
     "shell.execute_reply.started": "2024-12-31T16:59:02.543158Z"
    },
    "id": "M8oG9w6AYlAp",
    "outputId": "411bbb57-0fc1-42d6-8453-6692584c3114",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:2673: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:1472: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'Fiat, Bugatti, Benz, Miller',\n",
       " 'coordinates': [(0, 0), (3, 0), (7, 0), (8, 0)],\n",
       " 'cells': ['Fiat', 'Bugatti', 'Benz', 'Miller'],\n",
       " 'aggregator': 'NONE'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer_from_table(table, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T17:00:45.398067Z",
     "iopub.status.busy": "2024-12-31T17:00:45.397708Z",
     "iopub.status.idle": "2024-12-31T17:00:45.444961Z",
     "shell.execute_reply": "2024-12-31T17:00:45.444285Z",
     "shell.execute_reply.started": "2024-12-31T17:00:45.398040Z"
    },
    "id": "50g_9v-uEAPi",
    "outputId": "aece309c-3130-4bc6-a0d1-24b33a844c70",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a47f1e110214a84a5aa1482bba6e0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query embedding shape: (1, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rationale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1839</td>\n",
       "      <td>Robert Hare</td>\n",
       "      <td>Philadelphia , Pennsylvania</td>\n",
       "      <td>Inventor of the oxy-hydrogen blowpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1862</td>\n",
       "      <td>John Ericsson</td>\n",
       "      <td>New York , New York</td>\n",
       "      <td>His work improved the field of heat management...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1865</td>\n",
       "      <td>Daniel Treadwell</td>\n",
       "      <td>Cambridge , Massachusetts</td>\n",
       "      <td>Heat management . He was awarded especially fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1866</td>\n",
       "      <td>Alvan Clark</td>\n",
       "      <td>Cambridge , Massachusetts</td>\n",
       "      <td>Improved refracting telescopes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1869</td>\n",
       "      <td>George Henry Corliss</td>\n",
       "      <td>Providence , Rhode Island</td>\n",
       "      <td>For improving the steam engine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                  Name                     Location  \\\n",
       "0  1839           Robert Hare  Philadelphia , Pennsylvania   \n",
       "1  1862         John Ericsson          New York , New York   \n",
       "2  1865      Daniel Treadwell    Cambridge , Massachusetts   \n",
       "3  1866           Alvan Clark    Cambridge , Massachusetts   \n",
       "4  1869  George Henry Corliss    Providence , Rhode Island   \n",
       "\n",
       "                                           Rationale  \n",
       "0              Inventor of the oxy-hydrogen blowpipe  \n",
       "1  His work improved the field of heat management...  \n",
       "2  Heat management . He was awarded especially fo...  \n",
       "3                     Improved refracting telescopes  \n",
       "4                     For improving the steam engine  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"which scientist is known for improving the steam engine?\"\n",
    "table = query_pinecone(query)\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T17:00:49.503697Z",
     "iopub.status.busy": "2024-12-31T17:00:49.503342Z",
     "iopub.status.idle": "2024-12-31T17:00:49.625071Z",
     "shell.execute_reply": "2024-12-31T17:00:49.624082Z",
     "shell.execute_reply.started": "2024-12-31T17:00:49.503666Z"
    },
    "id": "tIBhlsF-ZYgI",
    "outputId": "7c0c41e1-5f59-4822-9e2b-bdb424e503e4",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:2673: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:1472: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'George Henry Corliss',\n",
       " 'coordinates': [(4, 1)],\n",
       " 'cells': ['George Henry Corliss'],\n",
       " 'aggregator': 'NONE'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer_from_table(table, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:59:11.524724Z",
     "iopub.status.busy": "2024-12-31T16:59:11.524391Z",
     "iopub.status.idle": "2024-12-31T16:59:11.570671Z",
     "shell.execute_reply": "2024-12-31T16:59:11.569914Z",
     "shell.execute_reply.started": "2024-12-31T16:59:11.524696Z"
    },
    "id": "uy1dDZSUphKw",
    "outputId": "b3df24b4-0fbd-40b3-98c0-c3c4d1b8c801",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b757dc68c736480eb854a6ff517f6005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query embedding shape: (1, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Resort Name</th>\n",
       "      <th>Geographic Atoll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asdhoo</td>\n",
       "      <td>Asdu Sun Island Resort</td>\n",
       "      <td>North Male Atoll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akirifushi</td>\n",
       "      <td>Oblu Select at Sangeli</td>\n",
       "      <td>North Male Atoll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baros</td>\n",
       "      <td>Baros Island Resort</td>\n",
       "      <td>North Male Atoll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biyaadhoo</td>\n",
       "      <td>Biyadhoo Island Resort</td>\n",
       "      <td>South Male Atoll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bodubandos</td>\n",
       "      <td>Bandos Maldives Resort</td>\n",
       "      <td>North Male Atoll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name             Resort Name  Geographic Atoll\n",
       "0      Asdhoo  Asdu Sun Island Resort  North Male Atoll\n",
       "1  Akirifushi  Oblu Select at Sangeli  North Male Atoll\n",
       "2       Baros     Baros Island Resort  North Male Atoll\n",
       "3   Biyaadhoo  Biyadhoo Island Resort  South Male Atoll\n",
       "4  Bodubandos  Bandos Maldives Resort  North Male Atoll"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the Maldivian island name for Oblu Select at Sangeli\tresort?\"\n",
    "table = query_pinecone(query)\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:59:17.210826Z",
     "iopub.status.busy": "2024-12-31T16:59:17.210505Z",
     "iopub.status.idle": "2024-12-31T16:59:17.296431Z",
     "shell.execute_reply": "2024-12-31T16:59:17.295555Z",
     "shell.execute_reply.started": "2024-12-31T16:59:17.210799Z"
    },
    "id": "jxmUzLlzuZbP",
    "outputId": "bead739a-4187-4764-bbfb-c14f3f1f4c5a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:2673: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:1472: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'Akirifushi',\n",
       " 'coordinates': [(1, 0)],\n",
       " 'cells': ['Akirifushi'],\n",
       " 'aggregator': 'NONE'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer_from_table(table, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7vUy_zP8DQB"
   },
   "source": [
    "As we can see, our Table QA system can retrieve the correct table from the Pinecone index and extract precise answers from the table. The TAPAS model we use supports more advanced queries. It has an aggregation head which indicates whether we need to count, sum, or average cells to answer the questions. Let's run some advanced queries that require aggregation to answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:59:29.705316Z",
     "iopub.status.busy": "2024-12-31T16:59:29.705007Z",
     "iopub.status.idle": "2024-12-31T16:59:29.751911Z",
     "shell.execute_reply": "2024-12-31T16:59:29.751119Z",
     "shell.execute_reply.started": "2024-12-31T16:59:29.705292Z"
    },
    "id": "cIGTeOMJxrGu",
    "outputId": "e9ef6122-c15f-42ab-c325-c1b59e6cced2",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59230f626dbb446594123860624eea73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query embedding shape: (1, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>GDP ( PPP , Peak Year ) millions of USD</th>\n",
       "      <th>Peak Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>China</td>\n",
       "      <td>27,804,953</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>India</td>\n",
       "      <td>11,321,280</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Russia</td>\n",
       "      <td>4,389,960</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>3,778,134</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>3,596,841</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank    Country GDP ( PPP , Peak Year ) millions of USD Peak Year\n",
       "0    1      China                              27,804,953      2020\n",
       "1    2      India                              11,321,280      2020\n",
       "2    3     Russia                               4,389,960      2019\n",
       "3    4  Indonesia                               3,778,134      2020\n",
       "4    5     Brazil                               3,596,841      2020"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what was the total GDP of China and Indonesia in 2020?\"\n",
    "table = query_pinecone(query)\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T16:59:33.578854Z",
     "iopub.status.busy": "2024-12-31T16:59:33.578492Z",
     "iopub.status.idle": "2024-12-31T16:59:33.665315Z",
     "shell.execute_reply": "2024-12-31T16:59:33.664562Z",
     "shell.execute_reply.started": "2024-12-31T16:59:33.578824Z"
    },
    "id": "O8zFOh8F0ut-",
    "outputId": "978ce1f8-6532-4710-d195-131c45ad6e36",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:2673: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:1472: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'SUM > 27,804,953, 3,778,134',\n",
       " 'coordinates': [(0, 2), (3, 2)],\n",
       " 'cells': ['27,804,953', '3,778,134'],\n",
       " 'aggregator': 'SUM'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer_from_table(table, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vB3s21XJEkpr"
   },
   "source": [
    "Here the QA system suggests the correct cells to add in order to get the total GDP of China and Indonesia in 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T17:01:13.779025Z",
     "iopub.status.busy": "2024-12-31T17:01:13.778640Z",
     "iopub.status.idle": "2024-12-31T17:01:13.827115Z",
     "shell.execute_reply": "2024-12-31T17:01:13.826347Z",
     "shell.execute_reply.started": "2024-12-31T17:01:13.778958Z"
    },
    "id": "VsEup2NXAjjK",
    "outputId": "ce29bfb6-22d1-4fcf-b469-877e55b0a406",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de53e90554f46cfab8e389872d44650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query embedding shape: (1, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO 2 intensity ( kg/kWh )</th>\n",
       "      <th>Power station</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.58</td>\n",
       "      <td>Hazelwood Power Station , Victoria closed 31 M...</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.56</td>\n",
       "      <td>Edwardsport IGCC , Edwardsport , Indiana , clo...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.27</td>\n",
       "      <td>Frimmersdorf power plant , Grevenbroich</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.25</td>\n",
       "      <td>HR Milner Generating Station , Grande Cache , ...</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.18</td>\n",
       "      <td>C. TG . Portes Gil , Río Bravo</td>\n",
       "      <td>Mexico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CO 2 intensity ( kg/kWh )  \\\n",
       "0                      1.58   \n",
       "1                      1.56   \n",
       "2                      1.27   \n",
       "3                      1.25   \n",
       "4                      1.18   \n",
       "\n",
       "                                       Power station        Country  \n",
       "0  Hazelwood Power Station , Victoria closed 31 M...      Australia  \n",
       "1  Edwardsport IGCC , Edwardsport , Indiana , clo...  United States  \n",
       "2            Frimmersdorf power plant , Grevenbroich        Germany  \n",
       "3  HR Milner Generating Station , Grande Cache , ...         Canada  \n",
       "4                     C. TG . Portes Gil , Río Bravo         Mexico  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is the average carbon emission of power stations in australia, canada and germany?\"\n",
    "table = query_pinecone(query)\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-31T17:01:16.575021Z",
     "iopub.status.busy": "2024-12-31T17:01:16.574673Z",
     "iopub.status.idle": "2024-12-31T17:01:16.635428Z",
     "shell.execute_reply": "2024-12-31T17:01:16.634475Z",
     "shell.execute_reply.started": "2024-12-31T17:01:16.574957Z"
    },
    "id": "pYGooFcrGc8Q",
    "outputId": "67cc0dfc-b825-466c-cee7-978152f5ff69",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:2673: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:1472: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'AVERAGE > 1.58, 1.27, 1.25',\n",
       " 'coordinates': [(0, 0), (2, 0), (3, 0)],\n",
       " 'cells': ['1.58', '1.27', '1.25'],\n",
       " 'aggregator': 'AVERAGE'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer_from_table(table, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HG8lPC0ONWxx"
   },
   "source": [
    "As we can see, the QA system correctly identified which cells to average to answer our question."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0398823b05ac46b3bb0d5918698e92aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0806e30586ef45e1b5c6de273d4b820e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "0dcc27dac0a34f0597bee867b7a0c1f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10dba06df8a0422e9863eb2991922816": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "234b6430d08d424a8d19153a0f74bc52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f08de790d64a4e5f81705d4cbbf5968d",
       "IPY_MODEL_f453b86b909b40cb89d6636c7b7a5c9d",
       "IPY_MODEL_b4a30af0fbc144b48d295af549ba2d53"
      ],
      "layout": "IPY_MODEL_82e6aa18d2644f299625377308af5912"
     }
    },
    "2f88a69a0e1443ff9f91a4054d8e751b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "383da807081440a4956ff80a7093a60c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "409092d8468c4f82bc2b6cf2f0b48dd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a07f6ff6e9464b54aeda12df8232f6ac",
      "placeholder": "​",
      "style": "IPY_MODEL_e8f14835a2324e56bb5d4c862767c602",
      "value": " 0/0 [00:00&lt;?, ?it/s]"
     }
    },
    "4338622351e44f06bf6e47d700ffa41b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4556db45bd464c189e5b771cb0773480": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "527d87292efc4589b652841afbd4845c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0dcc27dac0a34f0597bee867b7a0c1f7",
      "placeholder": "​",
      "style": "IPY_MODEL_2f88a69a0e1443ff9f91a4054d8e751b",
      "value": " 313/313 [09:12&lt;00:00,  1.49s/it]"
     }
    },
    "56dafa49175849e29a68782c43735b9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "571b97905d8c49498a4f5bc6bcfcf573": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "82419e00d85542d4a40ba725ac938820": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4556db45bd464c189e5b771cb0773480",
      "placeholder": "​",
      "style": "IPY_MODEL_f91627aef80646c38455fe7b31ed9d40",
      "value": "100%"
     }
    },
    "82e6aa18d2644f299625377308af5912": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "872351e5e09f4a2b9f1c23b1316b6a36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f9194e661d484dc6ba249100ad7792da",
       "IPY_MODEL_b25799ff3cb94fada82e7a64b708a377",
       "IPY_MODEL_409092d8468c4f82bc2b6cf2f0b48dd9"
      ],
      "layout": "IPY_MODEL_0398823b05ac46b3bb0d5918698e92aa"
     }
    },
    "8e6f046688664ea2a8b4ad91067cb0a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9283fd1259da4411b22315e66f0fde4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_82419e00d85542d4a40ba725ac938820",
       "IPY_MODEL_e141a30db58d4fedb680cfdbb6156fe9",
       "IPY_MODEL_527d87292efc4589b652841afbd4845c"
      ],
      "layout": "IPY_MODEL_8e6f046688664ea2a8b4ad91067cb0a4"
     }
    },
    "972f7c08489b46b6bf74bd4bcf0ecaa9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a07f6ff6e9464b54aeda12df8232f6ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a186c7e967744c4d8d48778c36cdc08d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a36059ff9de34279b633d26231da05de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab5b4aa08da64a5ea08cb3ab407a1b88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b25799ff3cb94fada82e7a64b708a377": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0806e30586ef45e1b5c6de273d4b820e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_972f7c08489b46b6bf74bd4bcf0ecaa9",
      "value": 0
     }
    },
    "b4a30af0fbc144b48d295af549ba2d53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4338622351e44f06bf6e47d700ffa41b",
      "placeholder": "​",
      "style": "IPY_MODEL_10dba06df8a0422e9863eb2991922816",
      "value": " 443M/443M [00:29&lt;00:00, 13.3MB/s]"
     }
    },
    "e141a30db58d4fedb680cfdbb6156fe9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56dafa49175849e29a68782c43735b9e",
      "max": 313,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_571b97905d8c49498a4f5bc6bcfcf573",
      "value": 313
     }
    },
    "e8f14835a2324e56bb5d4c862767c602": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea8d8ce27d7746d9bb928fa87dd67610": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f08de790d64a4e5f81705d4cbbf5968d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab5b4aa08da64a5ea08cb3ab407a1b88",
      "placeholder": "​",
      "style": "IPY_MODEL_f7ef382b17294e9a890118bcc55cc879",
      "value": "Downloading: 100%"
     }
    },
    "f453b86b909b40cb89d6636c7b7a5c9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea8d8ce27d7746d9bb928fa87dd67610",
      "max": 442791751,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_383da807081440a4956ff80a7093a60c",
      "value": 442791751
     }
    },
    "f7ef382b17294e9a890118bcc55cc879": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f91627aef80646c38455fe7b31ed9d40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9194e661d484dc6ba249100ad7792da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a36059ff9de34279b633d26231da05de",
      "placeholder": "​",
      "style": "IPY_MODEL_a186c7e967744c4d8d48778c36cdc08d",
      "value": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
